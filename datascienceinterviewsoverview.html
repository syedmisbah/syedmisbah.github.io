<!DOCTYPE html>

<html class="js video maskImage placeholder" lang="en">
<!--<![endif]-->

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>The Data Scientist's Interview Guide</title>
    <meta name="author" content="Syed Misbah">

    <meta name="description" content="An exhaustive list of questions asked in Data Science Interviews">
    <meta name="keywords" content="data sciencemachine learningjob interviewsinterview questionsalgorithmsprobabilitydata science job interviews">

    <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width,minimum-scale=1,maximum-scale=1">

   
    <link href="./css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
     <script type="text/javascript" src="./css/jXHR.js.download"></script>
    <script id="facebook-jssdk" async="" src="./css/all.js.download"></script>
    <script type="text/javascript" async="" src="./css/ga.js.download"></script>
    <script src="./css/modernizr-2.0.js.download"></script>
    <script src="./css/jquery.min.js.download"></script>
    <script>
        !window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))
    </script>
    <script src="./css/octopress.js.download" type="text/javascript"></script>
    <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
    <link href="./css/css" rel="stylesheet" type="text/css">
    <link href="./css/css(1)" rel="stylesheet" type="text/css">



    <script type="text/javascript" async="" src="./css/embed.js.download"></script>
    <script type="text/javascript" async="" src="./css/widgets.js.download"></script>
    <script charset="utf-8" src="./css/button.e96bb6acc0f8bda511c0c46a84ee18e4.js.download"></script>
    <style type="text/css">
        .MathJax_Hover_Frame {
            border-radius: .25em;
            -webkit-border-radius: .25em;
            -moz-border-radius: .25em;
            -khtml-border-radius: .25em;
            box-shadow: 0px 0px 15px #83A;
            -webkit-box-shadow: 0px 0px 15px #83A;
            -moz-box-shadow: 0px 0px 15px #83A;
            -khtml-box-shadow: 0px 0px 15px #83A;
            border: 1px solid #A6D ! important;
            display: inline-block;
            position: absolute
        }
        
        .MathJax_Menu_Button .MathJax_Hover_Arrow {
            position: absolute;
            cursor: pointer;
            display: inline-block;
            border: 2px solid #AAA;
            border-radius: 4px;
            -webkit-border-radius: 4px;
            -moz-border-radius: 4px;
            -khtml-border-radius: 4px;
            font-family: 'Courier New', Courier;
            font-size: 9px;
            color: #F0F0F0
        }
        
        .MathJax_Menu_Button .MathJax_Hover_Arrow span {
            display: block;
            background-color: #AAA;
            border: 1px solid;
            border-radius: 3px;
            line-height: 0;
            padding: 4px
        }
        
        .MathJax_Hover_Arrow:hover {
            color: white!important;
            border: 2px solid #CCC!important
        }
        
        .MathJax_Hover_Arrow:hover span {
            background-color: #CCC!important
        }
    </style>
    <style type="text/css">
        #MathJax_About {
            position: fixed;
            left: 50%;
            width: auto;
            text-align: center;
            border: 3px outset;
            padding: 1em 2em;
            background-color: #DDDDDD;
            color: black;
            cursor: default;
            font-family: message-box;
            font-size: 120%;
            font-style: normal;
            text-indent: 0;
            text-transform: none;
            line-height: normal;
            letter-spacing: normal;
            word-spacing: normal;
            word-wrap: normal;
            white-space: nowrap;
            float: none;
            z-index: 201;
            border-radius: 15px;
            -webkit-border-radius: 15px;
            -moz-border-radius: 15px;
            -khtml-border-radius: 15px;
            box-shadow: 0px 10px 20px #808080;
            -webkit-box-shadow: 0px 10px 20px #808080;
            -moz-box-shadow: 0px 10px 20px #808080;
            -khtml-box-shadow: 0px 10px 20px #808080;
            filter: progid: DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')
        }
        
        #MathJax_About.MathJax_MousePost {
            outline: none
        }
        
        .MathJax_Menu {
            position: absolute;
            background-color: white;
            color: black;
            width: auto;
            padding: 2px;
            border: 1px solid #CCCCCC;
            margin: 0;
            cursor: default;
            font: menu;
            text-align: left;
            text-indent: 0;
            text-transform: none;
            line-height: normal;
            letter-spacing: normal;
            word-spacing: normal;
            word-wrap: normal;
            white-space: nowrap;
            float: none;
            z-index: 201;
            box-shadow: 0px 10px 20px #808080;
            -webkit-box-shadow: 0px 10px 20px #808080;
            -moz-box-shadow: 0px 10px 20px #808080;
            -khtml-box-shadow: 0px 10px 20px #808080;
            filter: progid: DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')
        }
        
        .MathJax_MenuItem {
            padding: 2px 2em;
            background: transparent
        }
        
        .MathJax_MenuArrow {
            position: absolute;
            right: .5em;
            padding-top: .25em;
            color: #666666;
            font-size: .75em
        }
        
        .MathJax_MenuActive .MathJax_MenuArrow {
            color: white
        }
        
        .MathJax_MenuArrow.RTL {
            left: .5em;
            right: auto
        }
        
        .MathJax_MenuCheck {
            position: absolute;
            left: .7em
        }
        
        .MathJax_MenuCheck.RTL {
            right: .7em;
            left: auto
        }
        
        .MathJax_MenuRadioCheck {
            position: absolute;
            left: 1em
        }
        
        .MathJax_MenuRadioCheck.RTL {
            right: 1em;
            left: auto
        }
        
        .MathJax_MenuLabel {
            padding: 2px 2em 4px 1.33em;
            font-style: italic
        }
        
        .MathJax_MenuRule {
            border-top: 1px solid #CCCCCC;
            margin: 4px 1px 0px
        }
        
        .MathJax_MenuDisabled {
            color: GrayText
        }
        
        .MathJax_MenuActive {
            background-color: Highlight;
            color: HighlightText
        }
        
        .MathJax_MenuDisabled:focus,
        .MathJax_MenuLabel:focus {
            background-color: #E8E8E8
        }
        
        .MathJax_ContextMenu:focus {
            outline: none
        }
        
        .MathJax_ContextMenu .MathJax_MenuItem:focus {
            outline: none
        }
        
        #MathJax_AboutClose {
            top: .2em;
            right: .2em
        }
        
        .MathJax_Menu .MathJax_MenuClose {
            top: -10px;
            left: -10px
        }
        
        .MathJax_MenuClose {
            position: absolute;
            cursor: pointer;
            display: inline-block;
            border: 2px solid #AAA;
            border-radius: 18px;
            -webkit-border-radius: 18px;
            -moz-border-radius: 18px;
            -khtml-border-radius: 18px;
            font-family: 'Courier New', Courier;
            font-size: 24px;
            color: #F0F0F0
        }
        
        .MathJax_MenuClose span {
            display: block;
            background-color: #AAA;
            border: 1.5px solid;
            border-radius: 18px;
            -webkit-border-radius: 18px;
            -moz-border-radius: 18px;
            -khtml-border-radius: 18px;
            line-height: 0;
            padding: 8px 0 6px
        }
        
        .MathJax_MenuClose:hover {
            color: white!important;
            border: 2px solid #CCC!important
        }
        
        .MathJax_MenuClose:hover span {
            background-color: #CCC!important
        }
        
        .MathJax_MenuClose:hover:focus {
            outline: none
        }
    </style>
    <style type="text/css">
        .MathJax_Preview .MJXf-math {
            color: inherit!important
        }
    </style>
    <style type="text/css">
        .MJX_Assistive_MathML {
            position: absolute!important;
            top: 0;
            left: 0;
            clip: rect(1px, 1px, 1px, 1px);
            padding: 1px 0 0 0!important;
            border: 0!important;
            height: 1px!important;
            width: 1px!important;
            overflow: hidden!important;
            display: block!important;
            -webkit-touch-callout: none;
            -webkit-user-select: none;
            -khtml-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            user-select: none
        }
        
        .MJX_Assistive_MathML.MJX_Assistive_MathML_Block {
            width: 100%!important
        }
    </style>
    <style type="text/css">
        #MathJax_Zoom {
            position: absolute;
            background-color: #F0F0F0;
            overflow: auto;
            display: block;
            z-index: 301;
            padding: .5em;
            border: 1px solid black;
            margin: 0;
            font-weight: normal;
            font-style: normal;
            text-align: left;
            text-indent: 0;
            text-transform: none;
            line-height: normal;
            letter-spacing: normal;
            word-spacing: normal;
            word-wrap: normal;
            white-space: nowrap;
            float: none;
            -webkit-box-sizing: content-box;
            -moz-box-sizing: content-box;
            box-sizing: content-box;
            box-shadow: 5px 5px 15px #AAAAAA;
            -webkit-box-shadow: 5px 5px 15px #AAAAAA;
            -moz-box-shadow: 5px 5px 15px #AAAAAA;
            -khtml-box-shadow: 5px 5px 15px #AAAAAA;
            filter: progid: DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')
        }
        
        #MathJax_ZoomOverlay {
            position: absolute;
            left: 0;
            top: 0;
            z-index: 300;
            display: inline-block;
            width: 100%;
            height: 100%;
            border: 0;
            padding: 0;
            margin: 0;
            background-color: white;
            opacity: 0;
            filter: alpha(opacity=0)
        }
        
        #MathJax_ZoomFrame {
            position: relative;
            display: inline-block;
            height: 0;
            width: 0
        }
        
        #MathJax_ZoomEventTrap {
            position: absolute;
            left: 0;
            top: 0;
            z-index: 302;
            display: inline-block;
            border: 0;
            padding: 0;
            margin: 0;
            background-color: white;
            opacity: 0;
            filter: alpha(opacity=0)
        }
    </style>
    <style type="text/css">
        .MathJax_Preview {
            color: #888
        }
        
        #MathJax_Message {
            position: fixed;
            left: 1em;
            bottom: 1.5em;
            background-color: #E6E6E6;
            border: 1px solid #959595;
            margin: 0px;
            padding: 2px 8px;
            z-index: 102;
            color: black;
            font-size: 80%;
            width: auto;
            white-space: nowrap
        }
        
        #MathJax_MSIE_Frame {
            position: absolute;
            top: 0;
            left: 0;
            width: 0px;
            z-index: 101;
            border: 0px;
            margin: 0px;
            padding: 0px
        }
        
        .MathJax_Error {
            color: #CC0000;
            font-style: italic
        }
    </style>
    <style type="text/css">
        .MJXp-script {
            font-size: .8em
        }
        
        .MJXp-right {
            -webkit-transform-origin: right;
            -moz-transform-origin: right;
            -ms-transform-origin: right;
            -o-transform-origin: right;
            transform-origin: right
        }
        
        .MJXp-bold {
            font-weight: bold
        }
        
        .MJXp-italic {
            font-style: italic
        }
        
        .MJXp-scr {
            font-family: MathJax_Script, 'Times New Roman', Times, STIXGeneral, serif
        }
        
        .MJXp-frak {
            font-family: MathJax_Fraktur, 'Times New Roman', Times, STIXGeneral, serif
        }
        
        .MJXp-sf {
            font-family: MathJax_SansSerif, 'Times New Roman', Times, STIXGeneral, serif
        }
        
        .MJXp-cal {
            font-family: MathJax_Caligraphic, 'Times New Roman', Times, STIXGeneral, serif
        }
        
        .MJXp-mono {
            font-family: MathJax_Typewriter, 'Times New Roman', Times, STIXGeneral, serif
        }
        
        .MJXp-largeop {
            font-size: 150%
        }
        
        .MJXp-largeop.MJXp-int {
            vertical-align: -.2em
        }
        
        .MJXp-math {
            display: inline-block;
            line-height: 1.2;
            text-indent: 0;
            font-family: 'Times New Roman', Times, STIXGeneral, serif;
            white-space: nowrap;
            border-collapse: collapse
        }
        
        .MJXp-display {
            display: block;
            text-align: center;
            margin: 1em 0
        }
        
        .MJXp-math span {
            display: inline-block
        }
        
        .MJXp-box {
            display: block!important;
            text-align: center
        }
        
        .MJXp-box:after {
            content: " "
        }
        
        .MJXp-rule {
            display: block!important;
            margin-top: .1em
        }
        
        .MJXp-char {
            display: block!important
        }
        
        .MJXp-mo {
            margin: 0 .15em
        }
        
        .MJXp-mfrac {
            margin: 0 .125em;
            vertical-align: .25em
        }
        
        .MJXp-denom {
            display: inline-table!important;
            width: 100%
        }
        
        .MJXp-denom > * {
            display: table-row!important
        }
        
        .MJXp-surd {
            vertical-align: top
        }
        
        .MJXp-surd > * {
            display: block!important
        }
        
        .MJXp-script-box > * {
            display: table!important;
            height: 50%
        }
        
        .MJXp-script-box > * > * {
            display: table-cell!important;
            vertical-align: top
        }
        
        .MJXp-script-box > *:last-child > * {
            vertical-align: bottom
        }
        
        .MJXp-script-box > * > * > * {
            display: block!important
        }
        
        .MJXp-mphantom {
            visibility: hidden
        }
        
        .MJXp-munderover {
            display: inline-table!important
        }
        
        .MJXp-over {
            display: inline-block!important;
            text-align: center
        }
        
        .MJXp-over > * {
            display: block!important
        }
        
        .MJXp-munderover > * {
            display: table-row!important
        }
        
        .MJXp-mtable {
            vertical-align: .25em;
            margin: 0 .125em
        }
        
        .MJXp-mtable > * {
            display: inline-table!important;
            vertical-align: middle
        }
        
        .MJXp-mtr {
            display: table-row!important
        }
        
        .MJXp-mtd {
            display: table-cell!important;
            text-align: center;
            padding: .5em 0 0 .5em
        }
        
        .MJXp-mtr > .MJXp-mtd:first-child {
            padding-left: 0
        }
        
        .MJXp-mtr:first-child > .MJXp-mtd {
            padding-top: 0
        }
        
        .MJXp-mlabeledtr {
            display: table-row!important
        }
        
        .MJXp-mlabeledtr > .MJXp-mtd:first-child {
            padding-left: 0
        }
        
        .MJXp-mlabeledtr:first-child > .MJXp-mtd {
            padding-top: 0
        }
        
        .MJXp-merror {
            background-color: #FFFF88;
            color: #CC0000;
            border: 1px solid #CC0000;
            padding: 1px 3px;
            font-style: normal;
            font-size: 90%
        }
        
        .MJXp-scale0 {
            -webkit-transform: scaleX(.0);
            -moz-transform: scaleX(.0);
            -ms-transform: scaleX(.0);
            -o-transform: scaleX(.0);
            transform: scaleX(.0)
        }
        
        .MJXp-scale1 {
            -webkit-transform: scaleX(.1);
            -moz-transform: scaleX(.1);
            -ms-transform: scaleX(.1);
            -o-transform: scaleX(.1);
            transform: scaleX(.1)
        }
        
        .MJXp-scale2 {
            -webkit-transform: scaleX(.2);
            -moz-transform: scaleX(.2);
            -ms-transform: scaleX(.2);
            -o-transform: scaleX(.2);
            transform: scaleX(.2)
        }
        
        .MJXp-scale3 {
            -webkit-transform: scaleX(.3);
            -moz-transform: scaleX(.3);
            -ms-transform: scaleX(.3);
            -o-transform: scaleX(.3);
            transform: scaleX(.3)
        }
        
        .MJXp-scale4 {
            -webkit-transform: scaleX(.4);
            -moz-transform: scaleX(.4);
            -ms-transform: scaleX(.4);
            -o-transform: scaleX(.4);
            transform: scaleX(.4)
        }
        
        .MJXp-scale5 {
            -webkit-transform: scaleX(.5);
            -moz-transform: scaleX(.5);
            -ms-transform: scaleX(.5);
            -o-transform: scaleX(.5);
            transform: scaleX(.5)
        }
        
        .MJXp-scale6 {
            -webkit-transform: scaleX(.6);
            -moz-transform: scaleX(.6);
            -ms-transform: scaleX(.6);
            -o-transform: scaleX(.6);
            transform: scaleX(.6)
        }
        
        .MJXp-scale7 {
            -webkit-transform: scaleX(.7);
            -moz-transform: scaleX(.7);
            -ms-transform: scaleX(.7);
            -o-transform: scaleX(.7);
            transform: scaleX(.7)
        }
        
        .MJXp-scale8 {
            -webkit-transform: scaleX(.8);
            -moz-transform: scaleX(.8);
            -ms-transform: scaleX(.8);
            -o-transform: scaleX(.8);
            transform: scaleX(.8)
        }
        
        .MJXp-scale9 {
            -webkit-transform: scaleX(.9);
            -moz-transform: scaleX(.9);
            -ms-transform: scaleX(.9);
            -o-transform: scaleX(.9);
            transform: scaleX(.9)
        }
        
        .MathJax_PHTML .noError {
            vertical-align: ;
            font-size: 90%;
            text-align: left;
            color: black;
            padding: 1px 3px;
            border: 1px solid
        }
    </style>
    <style type="text/css">
        .MathJax_Display {
            text-align: center;
            margin: 1em 0em;
            position: relative;
            display: block!important;
            text-indent: 0;
            max-width: none;
            max-height: none;
            min-width: 0;
            min-height: 0;
            width: 100%
        }
        
        .MathJax .merror {
            background-color: #FFFF88;
            color: #CC0000;
            border: 1px solid #CC0000;
            padding: 1px 3px;
            font-style: normal;
            font-size: 90%
        }
        
        .MathJax .MJX-monospace {
            font-family: monospace
        }
        
        .MathJax .MJX-sans-serif {
            font-family: sans-serif
        }
        
        #MathJax_Tooltip {
            background-color: InfoBackground;
            color: InfoText;
            border: 1px solid black;
            box-shadow: 2px 2px 5px #AAAAAA;
            -webkit-box-shadow: 2px 2px 5px #AAAAAA;
            -moz-box-shadow: 2px 2px 5px #AAAAAA;
            -khtml-box-shadow: 2px 2px 5px #AAAAAA;
            filter: progid: DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true');
            padding: 3px 4px;
            z-index: 401;
            position: absolute;
            left: 0;
            top: 0;
            width: auto;
            height: auto;
            display: none
        }
        
        .MathJax {
            display: inline;
            font-style: normal;
            font-weight: normal;
            line-height: normal;
            font-size: 100%;
            font-size-adjust: none;
            text-indent: 0;
            text-align: left;
            text-transform: none;
            letter-spacing: normal;
            word-spacing: normal;
            word-wrap: normal;
            white-space: nowrap;
            float: none;
            direction: ltr;
            max-width: none;
            max-height: none;
            min-width: 0;
            min-height: 0;
            border: 0;
            padding: 0;
            margin: 0
        }
        
        .MathJax:focus,
        body:focus .MathJax {
            display: inline-table
        }
        
        .MathJax.MathJax_FullWidth {
            text-align: center;
            display: table-cell!important;
            width: 10000em!important
        }
        
        .MathJax img,
        .MathJax nobr,
        .MathJax a {
            border: 0;
            padding: 0;
            margin: 0;
            max-width: none;
            max-height: none;
            min-width: 0;
            min-height: 0;
            vertical-align: 0;
            line-height: normal;
            text-decoration: none
        }
        
        img.MathJax_strut {
            border: 0!important;
            padding: 0!important;
            margin: 0!important;
            vertical-align: 0!important
        }
        
        .MathJax span {
            display: inline;
            position: static;
            border: 0;
            padding: 0;
            margin: 0;
            vertical-align: 0;
            line-height: normal;
            text-decoration: none
        }
        
        .MathJax nobr {
            white-space: nowrap!important
        }
        
        .MathJax img {
            display: inline!important;
            float: none!important
        }
        
        .MathJax * {
            transition: none;
            -webkit-transition: none;
            -moz-transition: none;
            -ms-transition: none;
            -o-transition: none
        }
        
        .MathJax_Processing {
            visibility: hidden;
            position: fixed;
            width: 0;
            height: 0;
            overflow: hidden
        }
        
        .MathJax_Processed {
            display: none!important
        }
        
        .MathJax_ExBox {
            display: block!important;
            overflow: hidden;
            width: 1px;
            height: 60ex;
            min-height: 0;
            max-height: none
        }
        
        .MathJax .MathJax_EmBox {
            display: block!important;
            overflow: hidden;
            width: 1px;
            height: 60em;
            min-height: 0;
            max-height: none
        }
        
        .MathJax_LineBox {
            display: table!important
        }
        
        .MathJax_LineBox span {
            display: table-cell!important;
            width: 10000em!important;
            min-width: 0;
            max-width: none;
            padding: 0;
            border: 0;
            margin: 0
        }
        
        .MathJax .MathJax_HitBox {
            cursor: text;
            background: white;
            opacity: 0;
            filter: alpha(opacity=0)
        }
        
        .MathJax .MathJax_HitBox * {
            filter: none;
            opacity: 1;
            background: transparent
        }
        
        #MathJax_Tooltip * {
            filter: none;
            opacity: 1;
            background: transparent
        }
        
        @font-face {
            font-family: MathJax_Main;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Main-bold;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Main-italic;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Math-italic;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Caligraphic;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Size1;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Size2;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Size3;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.1') format('opentype')
        }
        
        @font-face {
            font-family: MathJax_Size4;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.1') format('opentype')
        }
        
        .MathJax .noError {
            vertical-align: ;
            font-size: 90%;
            text-align: left;
            color: black;
            padding: 1px 3px;
            border: 1px solid
        }
    </style>
    <style type="text/css">
        @font-face {
            font-family: MathJax_AMS;
            src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf?V=2.7.1') format('opentype')
        }
    </style>
    <link rel="preload" as="style" href="https://c.disquscdn.com/next/embed/styles/lounge.d49f53e192b9080ef8880a7c9b24f1c3.css">
    <link rel="preload" as="script" href="https://c.disquscdn.com/next/embed/common.bundle.81998d48c30a90f1e372f73e226bece4.js">
    <link rel="preload" as="script" href="https://c.disquscdn.com/next/embed/lounge.bundle.eb7b5137116db258599fe20d5d9253f6.js">
    <link rel="preload" as="script" href="https://disqus.com/next/config.js">
    <style type="text/css">
        .fb_hidden {
            position: absolute;
            top: -10000px;
            z-index: 10001
        }
        
        .fb_reposition {
            overflow: hidden;
            position: relative
        }
        
        .fb_invisible {
            display: none
        }
        
        .fb_reset {
            background: none;
            border: 0;
            border-spacing: 0;
            color: #000;
            cursor: auto;
            direction: ltr;
            font-family: "lucida grande", tahoma, verdana, arial, sans-serif;
            font-size: 11px;
            font-style: normal;
            font-variant: normal;
            font-weight: normal;
            letter-spacing: normal;
            line-height: 1;
            margin: 0;
            overflow: visible;
            padding: 0;
            text-align: left;
            text-decoration: none;
            text-indent: 0;
            text-shadow: none;
            text-transform: none;
            visibility: visible;
            white-space: normal;
            word-spacing: normal
        }
        
        .fb_reset>div {
            overflow: hidden
        }
        
        @keyframes fb_transform {
            from {
                opacity: 0;
                transform: scale(.95)
            }
            to {
                opacity: 1;
                transform: scale(1)
            }
        }
        
        .fb_animate {
            animation: fb_transform .3s forwards
        }
        
        .fb_dialog {
            background: rgba(82, 82, 82, .7);
            position: absolute;
            top: -10000px;
            z-index: 10001
        }
        
        .fb_dialog_advanced {
            border-radius: 8px;
            padding: 10px
        }
        
        .fb_dialog_content {
            background: #fff;
            color: #373737
        }
        
        .fb_dialog_close_icon {
            background: url(https://static.xx.fbcdn.net/rsrc.php/v3/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 0 transparent;
            cursor: pointer;
            display: block;
            height: 15px;
            position: absolute;
            right: 18px;
            top: 17px;
            width: 15px
        }
        
        .fb_dialog_mobile .fb_dialog_close_icon {
            left: 5px;
            right: auto;
            top: 5px
        }
        
        .fb_dialog_padding {
            background-color: transparent;
            position: absolute;
            width: 1px;
            z-index: -1
        }
        
        .fb_dialog_close_icon:hover {
            background: url(https://static.xx.fbcdn.net/rsrc.php/v3/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 -15px transparent
        }
        
        .fb_dialog_close_icon:active {
            background: url(https://static.xx.fbcdn.net/rsrc.php/v3/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 -30px transparent
        }
        
        .fb_dialog_iframe {
            line-height: 0
        }
        
        .fb_dialog_content .dialog_title {
            background: #6d84b4;
            border: 1px solid #365899;
            color: #fff;
            font-size: 14px;
            font-weight: bold;
            margin: 0
        }
        
        .fb_dialog_content .dialog_title>span {
            background: url(https://static.xx.fbcdn.net/rsrc.php/v3/yd/r/Cou7n-nqK52.gif) no-repeat 5px 50%;
            float: left;
            padding: 5px 0 7px 26px
        }
        
        body.fb_hidden {
            height: 100%;
            left: 0;
            margin: 0;
            overflow: visible;
            position: absolute;
            top: -10000px;
            transform: none;
            width: 100%
        }
        
        .fb_dialog.fb_dialog_mobile.loading {
            background: url(https://static.xx.fbcdn.net/rsrc.php/v3/ya/r/3rhSv5V8j3o.gif) white no-repeat 50% 50%;
            min-height: 100%;
            min-width: 100%;
            overflow: hidden;
            position: absolute;
            top: 0;
            z-index: 10001
        }
        
        .fb_dialog.fb_dialog_mobile.loading.centered {
            background: none;
            height: auto;
            min-height: initial;
            min-width: initial;
            width: auto
        }
        
        .fb_dialog.fb_dialog_mobile.loading.centered #fb_dialog_loader_spinner {
            width: 100%
        }
        
        .fb_dialog.fb_dialog_mobile.loading.centered .fb_dialog_content {
            background: none
        }
        
        .loading.centered #fb_dialog_loader_close {
            clear: both;
            color: #fff;
            display: block;
            font-size: 18px;
            padding-top: 20px
        }
        
        #fb-root #fb_dialog_ipad_overlay {
            background: rgba(0, 0, 0, .4);
            bottom: 0;
            left: 0;
            min-height: 100%;
            position: absolute;
            right: 0;
            top: 0;
            width: 100%;
            z-index: 10000
        }
        
        #fb-root #fb_dialog_ipad_overlay.hidden {
            display: none
        }
        
        .fb_dialog.fb_dialog_mobile.loading iframe {
            visibility: hidden
        }
        
        .fb_dialog_mobile .fb_dialog_iframe {
            position: sticky;
            top: 0
        }
        
        .fb_dialog_content .dialog_header {
            background: linear-gradient(from(#738aba), to(#2c4987));
            border-bottom: 1px solid;
            border-color: #1d3c78;
            box-shadow: white 0 1px 1px -1px inset;
            color: #fff;
            font: bold 14px Helvetica, sans-serif;
            text-overflow: ellipsis;
            text-shadow: rgba(0, 30, 84, .296875) 0 -1px 0;
            vertical-align: middle;
            white-space: nowrap
        }
        
        .fb_dialog_content .dialog_header table {
            height: 43px;
            width: 100%
        }
        
        .fb_dialog_content .dialog_header td.header_left {
            font-size: 12px;
            padding-left: 5px;
            vertical-align: middle;
            width: 60px
        }
        
        .fb_dialog_content .dialog_header td.header_right {
            font-size: 12px;
            padding-right: 5px;
            vertical-align: middle;
            width: 60px
        }
        
        .fb_dialog_content .touchable_button {
            background: linear-gradient(from(#4267B2), to(#2a4887));
            background-clip: padding-box;
            border: 1px solid #29487d;
            border-radius: 3px;
            display: inline-block;
            line-height: 18px;
            margin-top: 3px;
            max-width: 85px;
            padding: 4px 12px;
            position: relative
        }
        
        .fb_dialog_content .dialog_header .touchable_button input {
            background: none;
            border: none;
            color: #fff;
            font: bold 12px Helvetica, sans-serif;
            margin: 2px -12px;
            padding: 2px 6px 3px 6px;
            text-shadow: rgba(0, 30, 84, .296875) 0 -1px 0
        }
        
        .fb_dialog_content .dialog_header .header_center {
            color: #fff;
            font-size: 16px;
            font-weight: bold;
            line-height: 18px;
            text-align: center;
            vertical-align: middle
        }
        
        .fb_dialog_content .dialog_content {
            background: url(https://static.xx.fbcdn.net/rsrc.php/v3/y9/r/jKEcVPZFk-2.gif) no-repeat 50% 50%;
            border: 1px solid #4a4a4a;
            border-bottom: 0;
            border-top: 0;
            height: 150px
        }
        
        .fb_dialog_content .dialog_footer {
            background: #f5f6f7;
            border: 1px solid #4a4a4a;
            border-top-color: #ccc;
            height: 40px
        }
        
        #fb_dialog_loader_close {
            float: left
        }
        
        .fb_dialog.fb_dialog_mobile .fb_dialog_close_button {
            text-shadow: rgba(0, 30, 84, .296875) 0 -1px 0
        }
        
        .fb_dialog.fb_dialog_mobile .fb_dialog_close_icon {
            visibility: hidden
        }
        
        #fb_dialog_loader_spinner {
            animation: rotateSpinner 1.2s linear infinite;
            background-color: transparent;
            background-image: url(https://static.xx.fbcdn.net/rsrc.php/v3/yD/r/t-wz8gw1xG1.png);
            background-position: 50% 50%;
            background-repeat: no-repeat;
            height: 24px;
            width: 24px
        }
        
        @keyframes rotateSpinner {
            0% {
                transform: rotate(0deg)
            }
            100% {
                transform: rotate(360deg)
            }
        }
        
        .fb_iframe_widget {
            display: inline-block;
            position: relative
        }
        
        .fb_iframe_widget span {
            display: inline-block;
            position: relative;
            text-align: justify
        }
        
        .fb_iframe_widget iframe {
            position: absolute
        }
        
        .fb_iframe_widget_fluid_desktop,
        .fb_iframe_widget_fluid_desktop span,
        .fb_iframe_widget_fluid_desktop iframe {
            max-width: 100%
        }
        
        .fb_iframe_widget_fluid_desktop iframe {
            min-width: 220px;
            position: relative
        }
        
        .fb_iframe_widget_lift {
            z-index: 1
        }
        
        .fb_iframe_widget_fluid {
            display: inline
        }
        
        .fb_iframe_widget_fluid span {
            width: 100%
        }
    </style>
</head>

<body>
    <div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;">
        <div id="MathJax_Hidden"></div>
    </div>
    <div id="MathJax_Message" style="display: none;"></div>
    <header role="banner">
        <hgroup>
            <h1><a href="http://syedmisbah.github.io/">Data Science Interviews</a></h1>


        </hgroup>

    </header>
  
    <div id="main">
        <div id="content">
            <div>
                <article role="article">

                    <!-- <header>
                        <h1 class="entry-title">Interviews</h1>
                       
                    </header> -->

                    <p>This list <strike>might</strike> does look scary at first, but it&#8217;s highly unlikely that you will be asked all of these questions will be asked during one interview. Very few people(proabably Ph.D +) will actually know all of this.
                        But the idea is to cover everything as exhaustively as possible.</p>

<p>If you landed here by mistake, go back to my home page <a href="index.html">here.</a></p>



<h2>My experience for a senior data scientist role at a medium sized airline</h2>

<p>
        I interviewed for this position about 2 months ago. The first call was with a recruiter that was very straight forward (tell me about your background, etc.) plus a simple business question (what factors would go if you wanted to improve the turn around time of aircrafts). 
        
        The second interview was with a current data scientist was ~50% machine learning algorithms(basics and core ML) and 50% SQL and Big Data. We logged into a shared browser program that had the option to write in Python, SQL, etc. Some of the questions that were asked were:</p>

        <ul>
<li>What's the difference between SGD, Mini Batch GD and Gradient Descent</li>
<li>What does a 1x1 convolution net used for?</li>
<li>What would you do if you had a highly imbalanced dataset in a classification problem? </li>
<li>How would you build a classifier to determine the gender of a Twitter user given the corpus of their tweets.  How would you scale it to a million people, a billion, live streaming data? How did you train it, how do you periodically check it's valid? What modeling framework did you use and can you explain it at a high level? What about a mathematical one?</li>
<li>Imagine a test with a true positive rate of 1 and false positive rate of 5%. Imagine a population with a 1/1000 rate of having the condition the test identifies. Given a positive test, what is the probability of having that condition?</li>
<li>Write a complex SQL query using window functions to do solve some business problem - I fucked this one up?</li>
<li>Is the slope and gradient the same? Mathematically and intuitively?</li>
  <li>Tell me about list comprehension, generators, pandas, sklearn, etc. </li>   
        <li>Explain the difference between L1 and L2 regularization methods?</li>
        
        <li>Tell me the difference between an inner join, left join/right join, and union?</li>
    
        
        <li>You have a data set containing 100K rows, and 100 columns, with one of those columns being our dependent variable for a problem we'd like to solve. How can we quickly identify which columns will be helpful in predicting the dependent variable. Identify two techniques and explain them to me as though I were 5 years old.</li>
        
        <li>What is the Central Limit Theorem and why is it important in data science?</li>

        
        <li>Explain the 80/20 rule, and tell me about it's importance in model validation.</li>
        
        <li>In your opinion, which is more important when designing a machine learning model: Model performance? or model accuracy?</li>
        
        <li>What is one way that you would handle an imbalanced data set that's being used for prediction? (i.e. vastly more negative classes than positive classes.)</li>
        
        <li>Explain the following parts of a linear regression to me: p-value, coefficient, R-Squared value. What is the significance of each of these components and what assumptions do we hold when creating a linear regression?</li>
        
   
        
        <li>Explain like I'm 5: K-Means clustering algorithm.</li>
        
        <li>I have two models of comparable accuracy and computational performance. Which one should I choose for production and why?</li>

</ul>






<p>
        The above list is bits and peices. To cover things more exhaustively, read on. This includes content that I've collected over the years. </p>




<h2 id="table-of-content">Things to cover (incl. questions I was asked)</h2>

<!-- [TOC] -->

<ul>
<li><a href="#background-questions">Background Questions</a></li>
<li><a href="#process">Process</a></li>
<li><a href="#mathematics">Mathematics</a><ul>
<li><a href="#linear-algebra">Linear Algebra</a></li>
<li><a href="#other-areas">Other Areas</a></li></ul></li>
<li><a href="#probability-and-statistics">Probability and Statistics</a><ul>
<li><a href="#basic-probability">Basic Probability</a></li>
<li><a href="#distributions">Distributions</a></li>
<li><a href="#basic-statistics">Basic Statistics</a></li>
<li><a href="#experiment-design">Experiment Design</a></li>
<li><a href="#point-estimates">Point Estimates</a></li>
<li><a href="#testing">Testing</a></li>
<li><a href="#ab-tests">A/B Tests</a></li>
<li><a href="#bayesian-statistics">Bayesian Statistics</a></li>
<li><a href="#time-series">Time Series</a></li>
<li><a href="#advanced">Advanced</a></li></ul></li>
<li><a href="#machine-learning">Machine Learning</a><ul>
<li><a href="#general-ml-questions">General ML Questions</a></li>
<li><a href="#regression">Regression</a></li>
<li><a href="#classification">Classification</a></li>
<li><a href="#regularization">Regularization</a></li>
<li><a href="#dimensionality-reduction">Dimensionality Reduction</a></li>
<li><a href="#cluster-analysis">Cluster Analysis</a></li>
<li><a href="#optimization">Optimization</a></li>
<li><a href="#recommendation">Recommendation</a></li>
<li><a href="#feature-engineering">Feature Engineering</a></li>
<li><a href="#natural-language-processing">Natural Language Processing</a></li>
<li><a href="#meta-learning">Meta Learning</a></li>
<li><a href="#miscellanea">Miscellanea</a></li></ul></li>
<li><a href="#computer-science">DS and alogithms</a><ul>
<li><a href="#libraries-and-tools">Libraries and Tools</a></li>
<li><a href="#databases">Databases</a></li>
<li><a href="#distributed-systems-and-big-data">Distributed Systems and Big Data</a></li></ul></li>
<li><a href="#hands-on">Hands-On</a><ul>
<li><a href="#problem-to-solve">Problem to Solve</a></li>
<li><a href="#coding">Questions to ask</a></li>
</ul></li>

<p>&nbsp;</p>



<h2 id="background-questions">Background Questions</h2>

<p>Usually, interviews start with background questions: they can ask you to talk about yourself. This can also happen at the telephone interview stage.</p>

<p>For background questions be ready to talk about a summary of your career.</p>

<ul>
<li>Summarize your experience</li>
<li>What companies you worked at? What was your role?</li>
<li>Do you have a project portfolio? What projects you implemented? Discuss some of them in details</li>
<li>For graduating students: Tell me about your master thesis</li>
<li>For aspiring data scientists: Why do you want a career in data science?</li>
<li>Have you taken any data-science-related online courses? If yes, how many did you complete with a certificate?</li>
<li>Have you participated in any data science challenges? If yes, can you describe one of them? </li>
</ul>

<p>&nbsp;</p>



<h2 id="process">Process</h2>

<p>All Machine Learning, Data Mining and Data Science projects should follow some process, so there can be questions about it:</p>

<ul>
<li>Can you outline the steps in a data science project?</li>
<li>Have you heard of CRISP-DM (Cross Industry Standard Process for Data Mining)?</li>
</ul>
<br>

<p>CRISP-DM defines the following steps:</p>

<ul>
<li>Problem Definition</li>
<li>Data Understanding (or Data Exploration)</li>
<li>Data Preparation</li>
<li>Modeling</li>
<li>Evaluation</li>
<li>Deployment (for the production)</li>
</ul>
<br>
<p>So next you may discuss each of these steps in details</p>

<ul>
<li>What is the goal of each step?</li>
<li>What are possible activities at each step?</li>
</ul>

<p>&nbsp;</p>



<h2 id="mathematics">Mathematics</h2>

<p>Some background mathematics is necessary for doing Data Science, therefore you may expect math-related questions. On the other hand, for some Data Science positions there could be very few math questions, or none at all. In my opinion, it's always better to know the underlying theory when talking about Machine Learning algorithms, but your interviewers may have a different point of view.</p>

<p>&nbsp;</p>



<h3 id="linear-algebra">Linear Algebra</h3>

<p>Basic Linear Algebra questions might include:</p>

<ul>
<li>What is <script id="MathJax-Element-20" type="math/tex">A \mathbf x = \mathbf b</script>? How to solve it?</li>
<li>How do we multiply matrices?</li>
<li>What is an Eigenvalue? And what is an Eigenvector? What is Eigenvalue Decomposition or The Spectral Theorem?</li>
<li>What is Singular Value Decomposition?</li>
<li>You may expect Liner Algebra questions in the Machine Learning part of the interview (see below).</li>
</ul>

<p>&nbsp;</p>



<h3 id="other-areas">Other Areas</h3>

<ul>
<li>Discrete Mathematics and Logics are not that important for Data Science</li>
<li>Probability and Statistics are core skills and discussed in the next section</li>
<li>Calculus and Optimization are usually discussed in the Machine Learning part and usually when talking about a particular algorithm</li>
</ul>

<p>&nbsp;</p>



<h2 id="probability-and-statistics">Probability and Statistics</h2>

<p>Probability and Statistics give the foundation for Machine Learning, which makes them an important subject. It also may be useful if the company is doing some marketing or website optimization, so they could ask about related concepts such as A/B tests.</p>

<p>&nbsp;</p>



<h3 id="basic-probability">Basic Probability</h3>

<p>You can have a couple of simple questions to check your understanding of probability.</p>

<p>For example:</p>

<ul>
<li>Given two fair dices, what is the probability of getting scores that sum to 4? to 8?</li>
<li>A simple questions on Bayes rule: Imagine a test with a true positive rate of 100% and false positive rate of 5%. Imagine a population with a 1/1000 rate of having the condition the test identifies. Given a positive test, what is the probability of having that condition?</li>
</ul>

<p>&nbsp;</p>



<h3 id="distributions">Distributions</h3>

<p>You may expect questions about probability distributions:</p>

<ul>
<li>What is the normal distribution? Give an example of some variable that follows this distribution</li>
<li>What about log-normal?</li>
<li>Explain what a long tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and prediction problems?</li>
<li>How to check if a distribution is close to Normal? Why would you want to check it? What is a QQ Plot? </li>
<li>Give examples of data that does not have a Gaussian distribution, or log-normal. </li>
<li>Do you know what the exponential family is?</li>
<li>Do you know the Dirichlet distribution? the multinomial distribution?</li>
</ul>

<p>&nbsp;</p>



<h3 id="basic-statistics">Basic Statistics</h3>

<ul>
<li>What is the Laws of Large Numbers? Central Limit Theorem?</li>
<li>Why are they important for Statistics?</li>
<li>What summary statistics do you know?</li>
</ul>

<p>&nbsp;</p>



<h3 id="experiment-design">Experiment Design</h3>

<p>Designing experiments is an important part of Statistics, and it&#8217;s especially useful for doing A/B tests. </p>

<p>Sampling and Randomization</p>

<ul>
<li>Why do we need to sample and how? </li>
<li>Why is randomization important in experimental design?</li>
<li>Some 3rd party organization randomly assigned people to control and experiment groups. How can you verify that the assignment truly was random?</li>
<li>How do you calculate needed sample size? </li>
<li>Power analysis. What is it? </li>
</ul>
<br>
<p>Biases</p>

<ul>
<li>When you sample, what bias are you inflicting?</li>
<li>How do you control for biases?</li>
<li>What are some of the first things that come to mind when I do X in terms of biasing your data?</li>
</ul>
<br>
<p>Other questions</p>

<ul>
<li>What are confounding variables? </li>
</ul>

<p>&nbsp;</p>



<h3 id="point-estimates">Point Estimates</h3>

<p>Confidence intervals</p>

<ul>
<li>What is a point estimate? What is a confidence interval for it?</li>
<li>How are they constructed?</li>
<li>How to interpret confidence intervals?</li>
</ul>

<p>&nbsp;</p>



<h3 id="testing">Testing</h3>

<p>Hypothesis tests</p>

<ul>
<li>Why do we need hypothesis testing? What is P-Value?</li>
<li>What is the null hypothesis? How do we state it? </li>
<li>Do you know what Type-I/Type-II errors are?</li>
<li>What is <script id="MathJax-Element-21" type="math/tex">t</script>-Test/<script id="MathJax-Element-22" type="math/tex">F</script>-Test/ANOVA? When to use it? </li>
<li>How would you test if two populations have the same mean? What if you have 3 or 4 populations?</li>
<li>You applied ANOVA and it says that the means are different. How do you identify the populations where the differences are significant? </li>
<li>What is the distribution of p-value&#8217;s, in general?</li>
</ul>

<p>&nbsp;</p>



<h3 id="ab-tests">A/B Tests</h3>

<ul>
<li>What is A/B testing? How is it different from usual Hypothesis testing? </li>
<li>How can you prove that one improvement you&#8217;ve brought to an algorithm is really an improvement over not doing anything? How familiar are you with A/B testing? </li>
<li>How can we tell whether our website is improving?</li>
<li>What are the metrics to evaluate a website? A search engine? </li>
<li>What kind of metrics would you track for you music streaming website?</li>
<li>Common metrics: Engagement / retention rate, conversion, similar products / duplicates matching, how to measure them.</li>
<li>Real-life numbers and intuition: Expected user behavior, reasonable ranges for user signup / retention rate, session length / count, registered / unregistered users, deep / top-level engagement, spam rate, complaint rate, ads efficiency.</li>
</ul>

<p>&nbsp;</p>



<h3 id="time-series">Time Series</h3>

<ul>
<li>What is a time series? </li>
<li>Did you do any projects which involved dealing with time?</li>
<li>What is the difference between data for usual statistical analysis and time series data? </li>
<li>Have you used any of the following: Time series models, Cross-correlations with time lags, Correlograms, Spectral analysis, Signal processing and filtering techniques? If yes, in which context?</li>
<li>In time series modeling how can we deal with multiple types of seasonality like weekly and yearly seasonality?</li>
</ul>

<p>&nbsp;</p>



<h3 id="advanced">Advanced</h3>

<p>Resampling </p>

<ul>
<li>Explain what resampling methods are. Why they are useful. What are their limitations?</li>
<li>Bootstrapping - how and why it is used? </li>
<li>How to use resampling for hypothesis testing? Have you heard of Permutation Tests? </li>
<li>How would you apply resampling to time series data? </li>
</ul>

<p>&nbsp;</p>



<h2 id="machine-learning">Machine Learning</h2>

<p>In my experience, the Machine Learning part is usually the largest part of the interview. It may be a few basic questions, but it&#8217;s helpful to be prepared to more in-depth Machine Learning questions, especially if you claim to have worked with it on your CV. </p>



<h3 id="general-ml-questions">General ML Questions</h3>

<p>The ML part may start with something  like:</p>

<ul>
<li>What is the difference between supervised and unsupervised learning? Which algorithms are supervised learning and which are not? Why? </li>
<li>What is your favorite ML algorithm and why? </li>
</ul>
<br>
<p>And then go into details</p>

<p>&nbsp;</p>



<h3 id="regression">Regression</h3>

<ul>
<li>Describe the regression problem. Is it supervised learning? Why? </li>
<li>What is linear regression? Why is it called linear? </li>
<li>Discuss the bias-variance tradeoff.</li>
</ul>
<br>
<p>Linear Regression:</p>

<ul>
<li>What is Ordinary Least Squares Regression? How it can be learned? </li>
<li>Can you derive the OLS Regression formula? (For one-step solution)</li>
<li>Is model <script id="MathJax-Element-23" type="math/tex">Y \sim X_1 + X_2 + X_1 \, X_2</script> still linear? Why? </li>
<li>Do we always need the intercept term? When do we need it and when do we not? </li>
<li>What is collinearity and what to do with it? How to remove multicollinearity? </li>
<li>What if the design matrix is not full rank? </li>
<li>What is overfitting a regression model? What are ways to avoid it?</li>
<li>What is Ridge Regression? How is it different from OLS Regression? Why do we need it? </li>
<li>What is Lasso regression? How is it different from OLS and Ridge? </li>
</ul>
<br>
<p>Linear Regression assumptions:</p>

<ul>
<li>What are the assumptions required for linear regression?</li>
<li>What if some of these assumptions are violated? </li>
</ul>
<br>
<p>Significant features in Regression</p>

<ul>
<li>You would like to find significant features. How would you do that? </li>
<li>You fit a multiple regression to examine the effect of a particular feature. The feature comes back insignificant, but you believe it is significant. Why can it happen? </li>
<li>Your model considers the feature <script id="MathJax-Element-24" type="math/tex">X</script> significant, and <script id="MathJax-Element-25" type="math/tex">Z</script> is not, but you expected the opposite result. Why can it happen?</li>
</ul>
<br>
<p>Evaluation</p>

<ul>
<li>How to check is the regression model fits the data well? </li>
</ul>
<br>
<p>Other algorithms for regression</p>

<ul>
<li>Decision trees for regression</li>
<li><script id="MathJax-Element-26" type="math/tex">k</script>-Nearest Neighbors for regression. When to use? </li>
<li>Do you know others? E.g. Splines? LOESS/LOWESS? </li>
</ul>

<p>&nbsp;</p>



<h3 id="classification">Classification</h3>

<p>Basic:</p>

<ul>
<li>Can you describe what is the classification problem? </li>
<li>What is the simplest classification algorithm?</li>
<li>What classification algorithms do you know? Which one you like the most? </li>
</ul>
<br>
<p>Decision trees:</p>

<ul>
<li>What is a decision tree? </li>
<li>What are some business reasons you might want to use a decision tree model?</li>
<li>How do you build it? What impurity measures do you know? </li>
<li>Describe some of the different splitting rules used by different decision tree algorithms.</li>
<li>Is a big brushy tree always good? Why would you want to prune it? </li>
<li>Is it a good idea to combine multiple trees? </li>
<li>What is Random Forest? Why is it good?</li>
<li>Other ways to combine trees? What about boosting?</li>
</ul>
<br>
<p>Logistic regression:</p>

<ul>
<li>What is logistic regression? </li>
<li>How do we train a logistic regression model?</li>
<li>How do we interpret its coefficients?</li>
</ul>
<br>
<p>Support Vector Machines</p>

<ul>
<li>What is the maximal margin classifier? How this margin can be achieved and why is it beneficial?</li>
<li>How do we train SVM? What about hard SVM and soft SVM?</li>
<li>What is a kernel? What's the intuition behind the Kernel trick?</li>
<li>Which kernels do you know? How to choose a kernel? </li>
</ul>
<br>
<p>Neural Networks</p>

<ul>
<li>What is an Artificial Neural Network?</li>
<li>How to train an ANN? What is back propagation? </li>
<li>How does a neural network with three layers (one input layer, one inner layer and one output layer) compare to a logistic regression?</li>
<li>What is deep learning? What is CNN (Convolution Neural Network) or RNN (Recurrent Neural Network)? </li>
</ul>
<br>
<p>Other models: </p>

<ul>
<li>What other models do you know? </li>
<li>How can we use Naive Bayes classifier for categorical features? What if some features are numerical? </li>
<li>Tradeoffs between different types of classification models. How to choose the best one? </li>
<li>Compare logistic regression with decision trees and neural networks.</li>
</ul>

<p>&nbsp;</p>



<h3 id="regularization">Regularization</h3>

<ul>
<li>What is Regularization? </li>
<li>Which problem does Regularization try to solve? </li>
<li>What does it mean (practically) for a design matrix to be &#8220;ill-conditioned&#8221;?</li>
<li>When might you want to use ridge regression instead of traditional linear regression?</li>
<li>What is the difference between the <script id="MathJax-Element-27" type="math/tex">L_1</script> and <script id="MathJax-Element-28" type="math/tex">L_2</script> regularization?</li>
<li>Why (geometrically) does LASSO produce solutions with zero-valued coefficients (as opposed to ridge)?</li>
<li>Let us go through the derivation of OLS or Logistic Regression. What happens when we add <script id="MathJax-Element-29" type="math/tex">L_2</script> regularization? How do the derivations change? What if we replace <script id="MathJax-Element-30" type="math/tex">L_2</script> regularization with <script id="MathJax-Element-31" type="math/tex">L_1</script> regularization?</li>
</ul>

<p>&nbsp;</p>



<h3 id="dimensionality-reduction">Dimensionality Reduction</h3>

<p>Basics:</p>

<ul>
<li>What is the purpose of dimensionality reduction and why do we need it? </li>
<li>Are dimensionality reduction techniques supervised or not? Are all of them are (un)supervised? </li>
<li>What ways of reducing dimensionality do you know? </li>
<li>Is feature selection a dimensionality reduction technique? </li>
<li>What is the difference between feature selection and feature extraction? </li>
<li>Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?</li>
</ul>
<br>
<p>Principal Component Analysis:</p>

<ul>
<li>What is Principal Component Analysis (PCA)? What is the problem it solves? How is it related to eigenvalue decomposition (EVD)? </li>
<li>What&#8217;s the relationship between PCA and SVD? When SVD is better than EVD for PCA?</li>
<li>Under what conditions is PCA effective?</li>
<li>Why do we need to center data for PCA and what can happed if we don&#8217;t do it? Do we need to scale data for PCA? </li>
<li>Is PCA a linear model or not? Why? </li>
</ul><br>

<p>Other Dimensionality Reduction techniques:</p>

<ul>
<li>Do you know other Dimensionality Reduction techniques? </li>
<li>What is Independent Component Analysis (ICA)? What&#8217;s the difference between ICA and PCA? </li>
<li>Suppose you have a very sparse matrix where rows are highly dimensional. You project these rows on a random vector of relatively small dimensionality. Is it a valid dimensionality reduction technique or not? </li>
<li>Have you heard of Kernel PCA or other non-linear dimensionality reduction techniques? What about LLE (Locally Linear Embedding) or <script id="MathJax-Element-32" type="math/tex">t</script>-SNE (<script id="MathJax-Element-33" type="math/tex">t</script>-distributed Stochastic Neighbor Embedding)</li>
<li>What is Fisher Discriminant Analysis? How it is different from PCA? Is it supervised or not? </li>
</ul>

<p>&nbsp;</p>



<h3 id="cluster-analysis">Cluster Analysis</h3>

<ul>
<li>What is the cluster analysis problem?</li>
<li>Which cluster analysis methods you know? </li>
<li>Describe <script id="MathJax-Element-34" type="math/tex">K</script>-Means. What is the objective of <script id="MathJax-Element-35" type="math/tex">K</script>-Means? Can you describe the Lloyd algorithm? </li>
<li>How do you select <script id="MathJax-Element-36" type="math/tex">K</script> for K-Means? </li>
<li>How can you modify <script id="MathJax-Element-37" type="math/tex">K</script>-Means to produce soft class assignments?</li>
<li>How to assess the quality of clustering? </li>
<li>Describe any other cluster analysis method. E.g. DBSCAN.</li>
</ul>

<p>&nbsp;</p>



<h3 id="optimization">Optimization</h3>

<p>You may have some basic questions about optimization:</p>

<ul>
<li>What is the difference between a convex function and non-convex? </li>
<li>What is Gradient Descent Method?</li>
<li>Will Gradient Descent methods always converge to the same point?</li>
<li>What is a local optimum? </li>
<li>Is it always bad to have local optima?</li>
</ul>

<p>&nbsp;</p>



<h3 id="recommendation">Recommendation</h3>

<ul>
<li>What is a recommendation engine? How does it work?</li>
<li>Do you know about the Netflix Prize problem? How would you approach it?</li>
<li>How to do customer recommendation?</li>
<li>What is Collaborative Filtering?</li>
<li>How would you generate related searches for a search engine?</li>
<li>How would you suggest followers on Twitter?</li>
</ul>

<p>&nbsp;</p>



<h3 id="feature-engineering">Feature Engineering</h3>

<ul>
<li>How to apply Machine Learning to audio data, images, texts, graphs, etc? </li>
<li>What is Feature Engineering? Can you give an example? Why do we need it? </li>
<li>How to go from categorical variables to numerical? </li>
<li>What to do with categorical variables of high cardinality?</li>
</ul>

<p>&nbsp;</p>



<h3 id="natural-language-processing">Natural Language Processing</h3>

<p>If the company deals with text data, you can expect some questions on NLP and Information Retrieval:</p>

<ul>
<li>What is NLP? How is it related to Machine Learning? </li>
<li>How would you turn unstructured text data into structured data usable for ML models?</li>
<li>What is the Vector Space Model?</li>
<li>What is TF-IDF?</li>
<li>Which distances and similarity measures can we use to compare documents? What is cosine similarity? </li>
<li>Why do we remove stop words? When do we not remove them?</li>
<li>Language Models. What is <script id="MathJax-Element-38" type="math/tex">N</script>-Grams? </li>
<li>What is word2vec? How it can be used in NLP and IR?</li>
</ul>

<p>&nbsp;</p>



<h3 id="meta-learning">Meta Learning</h3>

<p>Feature Selection:</p>

<ul>
<li>Are all features equally good? </li>
<li>What are the downfalls of using too many or too few variables?</li>
<li>How many features should you use? How do you select the best features? </li>
<li>What is Feature Selection and why do we need it? </li>
<li>Describe several feature selection methods. Are these methods depend on the model or not?</li>
</ul><br>

<p>Model selection:</p>

<ul>
<li>You have built several different models. How would you select the best one? </li>
<li>You have one model and want to find the best set of parameters for this model. How would you do that? </li>
<li>How would you look for the best parameters? Do you know something else apart from grid search? </li>
<li>What is Cross-Validation? </li>
<li>What is 10-Fold CV?</li>
<li>What is the difference between holding out a validation set and doing 10-Fold CV?</li>
</ul>
<br>
<p>Model evaluation</p>

<ul>
<li>How do you know if your model overfits? </li>
<li>How do you assess the results of a logistic regression?</li>
<li>Which evaluation metrics you know? Something apart from accuracy?</li>
<li>Which is better: Too many false positives or too many false negatives?</li>
<li>What precision and recall are?</li>
<li>What is a ROC curve? What is AU ROC (AUC)? How to interpret the curve and AU ROC? </li>
<li>Do you know about Concordance or Lift? </li>
</ul>
<br>
<p>Discussion Questions:</p>

<ul>
<li>You have a marketing campaign and you want to send emails to users. You developed a model for predicting if a user will reply or not. How can you evaluate this model? Is there a chart you can use?</li>
</ul>

<p>&nbsp;</p>



<h3 id="miscellanea">Miscellanea</h3>

<p>Curse of Dimensionality</p>

<ul>
<li>What is Curse of Dimensionality? How does it affect distance and similarity measures? </li>
<li>What are the problems of large feature space? How does it affect different models, e.g. OLS? What about computational complexity? </li>
<li>What dimensionality reductions can be used for preprocessing the data?</li>
<li>What is the difference between density-sparse data and dimensionally-sparse data? </li>
</ul>
<br>
<p>Others </p>

<ul>
<li>You are training an image classifier with limited data. What are some ways you can augment your dataset?</li>
</ul>

<p>&nbsp;</p>



<h2 id="computer-science">DS and alogithms</h2>

<p>Knowledge in DS and alogithms is as important for Data Science as knowledge in Machine Learning. So you may get the same type of questions as for any software developer position, but possibly with lower expectations on your answers.</p>
<ul>
        <li>Given a list of timestamps in sequential order, return a list of lists grouped by weekly aggregation. </li>
        <li>Given a list of characters, a list of prior of probabilities for each character, and a matrix of probabilities for each character combination, return the optimal sequence for the highest probability.
            </li>
        <li>Given a log file with rows featuring a date, a number, and then a string of names, parse the log file and return the count of unique names aggregated by month.</li>
        <li>What is recursion?</li>

      
                <li>write regular expression to match legal IP addresses</li>
                <li>write any n log(n) sorting algorithm</li>
                <li>implement a tail-recursive factorial function</li>
                <li>find minimum of a rotated sorted array</li>
                <li>write a function that tests whether two strings are anagrams</li>
                <li>find duplicate lines in file. Do it in bash, in python, in mapreduce (your mapper function is fed lines of the file), in sql (the file is represented as a table with only one column “line”)</li>
                <li>an array contains n distinct numbers taken from 0, 1, 2, …, n, find the one that is missing from the array</li>
                <li>“content_actions” is a table that logs user activity.</li>
       
        </ul>



<p>&nbsp;</p>



<h3 id="libraries-and-tools">Libraries and Tools</h3>

<p>Apart from basics of Java/Scala/Python/etc, you may be asked about libraries for data analysis:</p>

<ul>
<li>Which libraries for data analysis do you know in Python/R/Java?</li>
<li>Have you used numpy, scipy, pandas, sklearn?</li>
<li>What are some features of the sklearn api that differentiate it from fitting models in R?</li>
<li>What are some features of pandas/sklearn that you like? Don't like? Same questions for R.</li>
<li>Why is &#8220;vectorization&#8221; such a powerful method for optimizing numerical code? What is going on that makes the code faster relative to alternatives like nested for loops?</li>
<li>When is it better to write your own code than using a data science software package?</li>
<li>State any 3 positive and negative aspects about your favorite statistical software.</li>
<li>Describe a difficult bug you&#8217;ve encountered and how you resolved it.</li>
<li>How does floating point affect precision of calculations? Equality tests?</li>
<li>What is BLAS? LAPACK?</li>
</ul>

<p>&nbsp;</p>



<h3 id="databases">Databases</h3>

<ul>
<li>Have you been involved in database design and data modeling?</li>
<li>SQL-Related questions: e.g. what is "group by"? </li>
<li>Or given some DB schema you may be asked to write a simple SQL query.</li>
<li>What is a &#8220;star schema&#8221;? &#8220;snowflake schema&#8221;?</li>
<li>Describe different NoSQL technologies you&#8217;re familiar with, what they are good at, and what they are bad at.</li>
</ul>

<p>&nbsp;</p>



<h3 id="distributed-systems-and-big-data">Distributed Systems and Big Data</h3>

<p>Basic &#8220;Big Data&#8221; questions:</p>

<ul>
<li>What is the biggest data set that you have processed and how did you process it? What was the result?</li>
<li>Have you used Apache Hadoop, Apache Spark, Apache Flink? Why? Have you used Apache Mahout? </li>
</ul>
<br>
<p>MapReduce</p>

<ul>
<li>What is MapReduce? Why is it &#8220;shared-nothing&#8221; architecture?</li>
<li>Can you implement word count in MapReduce? What about something a bit more complex like TF-IDF? Naive Bayes? </li>
<li>What is load balance? How to make sure a MapReduce application has good load balance? </li>
<li>Can you give examples where MapReduce does not work? </li>
<li>What are examples of &#8220;embarassingly parallelizable&#8221; algorithms?</li>
<li>How would you estimate the median of a dataset that is too big to hold in the memory?</li>
</ul>






<h2 id="hands-on">Hands-On</h2>

<p>Also, many interviews have a part which I call &#8220;hands-on&#8221;:  you are given some problem description and you are asked to solve it. You can just talk the interviewers through your solution or even be asked to sit and implement some parts. Sometimes there is also a test assignment to be done at home (prior to the interview). </p>

<p>&nbsp;</p>



<h3 id="problem-to-solve">Problem to Solve</h3>

<p>For example:</p>

<p>Assume that you are asked to lead a project on churn detection, and have dataset of known users who stopped using the service and ones who are still using. This data includes demographics and other features.</p>
<br>
<p>Do the following:</p>

<ol>
<li>Describe the methodology and model that you will chose to identify churn, and describe your thought process.</li>
<li>Think how would you communicate the results to the CEO? </li>
<li>Suppose in the dataset only 0.025 of users churned. How would you make it more balanced? </li>
</ol>
<br>
<p>Also:</p>

<ul>
<li>How would you implement it if you had one day? One month? One year? </li>
<li>How would your approach scale? </li>
</ul>
<br>
<p>Other problems: </p>

<ul>
<li>How would you approach identifying plagiarism? </li>
<li>How to find individual paid accounts shared by multiple users?</li>
<li>How to detect bogus reviews, or bogus Facebook accounts used for bad purposes?</li>
<li>Usually the domain of the problem is related to what the company is doing. If they&#8217;re doing marketing, it will most likely be marketing related. </li>
</ul>
<br>
<p>Additionally, you may be asked:</p>

<ul>
<li>How would you approach collecting the data if you didn&#8217;t have the dataset? </li>
</ul>
<br>
<p>I will be covering more of this in another post.</p>



<h3 id="coding">Questions to ask</h3>

<p>When you ask questios, be specific and make sure that the profile and team you're applying for are suited to your profile and persona </p>

<ul>
        <li>How big is the DS team?</li>
        <li>Maturity? How fast has it grown?</li>
        <li>Skill distribution on team?</li>
        <li>Tooling/development environment? (mainly to know if it's a linux/windows shop)</li>
        <li>Project methodology? Agile or other?</li>
        <li>Customer engagement model?</li>
        <li>How many in-flight projects do you have right now? How many past projects are you supporting?</li>
        <li>What is the long term vision for data science at this organization?</li>
        <li>Where do you see the Data Science team in a year? five?</li>
        <li>Major successes you feel comfortable sharing?</li>
        <li>An example of a failure you feel comfortable sharing?</li>
        <li>How much executive buy-in on DS initiatives?</li>
    </ul>


<p>&nbsp;</p>

<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Data Science Interview Questions &amp; Detailed Answers</h1>
</div>



<h2>Questions</h2>
<hr />
<div id="machine-learning-mathematics" class="section level3">
<h3>Machine Learning &amp; Mathematics</h3>
<ol style="list-style-type: decimal">
<li>What is cross-validation? How to do it right?</li>
<li>Is it better to design robust or accurate algorithms?</li>
<li>How to define/select metrics?</li>
<li>Explain what regularization is and why it is useful. What are the benefits and drawbacks of specific methods, such as ridge regression and lasso?</li>
<li>Explain what a local optimum is and why it is important in a specific context, such as K-means clustering. What are specific ways of determining if you have a local optimum problem? What can be done to avoid local optima?</li>
<li>Assume you need to generate a predictive model using multiple regression. Explain how you intend to validate this model<br /></li>
<li>Explain what precision and recall are. How do they relate to the ROC curve?</li>
<li>What is latent semantic indexing? What is it used for? What are the specific limitations of the method?</li>
<li>Explain what resampling methods are and why they are useful</li>
<li>What is principal component analysis? Explain the sort of problems you would use PCA for. Also explain its limitations as a method</li>
<li>Explain what a false positive and a false negative are. Why is it important these from each other? Provide examples when false positives are more important than false negatives, false negatives are more important than false positives and when these two types of errors are equally important</li>
<li>What is the difference between supervised learning and unsupervised learning? Give concrete examples</li>
<li>What does NLP stand for?</li>
<li>What are feature vectors?</li>
<li>When would you use random forests Vs SVM and why?</li>
<li>How do you take millions of users with 100’s transactions each, amongst 10k’s of products and group the users together in meaningful segments?</li>
<li>How do you know if one algorithm is better than other?</li>
<li>How do you test whether a new credit risk scoring model works?<br /></li>
<li>What is: collaborative filtering, n-grams, cosine distance?</li>
<li>What is better: good data or good models? And how do you define “good”? Is there a universal good model? Are there any models that are definitely not so good?</li>
<li>Why is naive Bayes so bad? How would you improve a spam detection algorithm that uses naive Bayes?</li>
<li>What are the drawbacks of linear model? Are you familiar with alternatives (Lasso, ridge regression, boosted trees)?</li>
<li>Do you think 50 small decision trees are better than a large one? Why?</li>
<li>Why is mean square error a bad measure of model performance? What would you suggest instead?</li>
<li>How can you prove that one improvement you’ve brought to an algorithm is really an improvement over not doing anything? Are you familiar with A/B testing?</li>
<li>What do you think about the idea of injecting noise in your data set to test the sensitivity of your models?</li>
<li>Do you know / used data reduction techniques other than PCA? What do you think of step-wise regression? What kind of step-wise techniques are you familiar with?</li>
<li>How would you define and measure the predictive power of a metric?</li>
<li>Do we always need the intercept term in a regression model?<br /></li>
<li>What are the assumptions required for linear regression? What if some of these assumptions are violated?</li>
<li>What is collinearity and what to do with it? How to remove multicollinearity?</li>
<li>How to check if the regression model fits the data well?</li>
<li>What is a decision tree?</li>
<li>What impurity measures do you know?</li>
<li>What is random forest? Why is it good?</li>
<li>How do we train a logistic regression model? How do we interpret its coefficients?</li>
<li>What is the maximal margin classifier? How this margin can be achieved and why is it beneficial? How do we train SVM?</li>
<li>What is a kernel? Explain the kernel trick</li>
<li>Which kernels do you know? How to choose a kernel?</li>
<li>Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?</li>
<li>(What is an Artificial Neural Network?) What is back propagation?</li>
<li>What is curse of dimensionality? How does it affect distance and similarity measures?</li>
<li>What is Ax=b? How to solve it?</li>
<li>How do we multiply matrices?</li>
<li>What is singular value decomposition? What is an eigenvalue? And what is an eigenvector?</li>
<li>What’s the relationship between PCA and SVD?</li>
<li>Can you derive the ordinary least square regression formula?</li>
<li>What is the difference between a convex function and non-convex?</li>
<li>What is gradient descent method? Will gradient descent methods always converge to the same point?</li>
<li>What the Newton’s method is?</li>
<li>Imagine you have N pieces of rope in a bucket. You reach in and grab one end-piece, then reach in and grab another end-piece, and tie those two together. What is the expected value of the number of loops in the bucket?</li>
</ol>
<hr />
</div>
</div>
<div id="statistics" class="section level2">
<h2>Statistics</h2>
<ol style="list-style-type: decimal">
<li>How do you assess the statistical significance of an insight?</li>
<li>Explain what a long-tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?<br /></li>
<li>What is the Central Limit Theorem? Explain it. Why is it important?<br /></li>
<li>What is statistical power?</li>
<li>Explain selection bias (with regard to a dataset, not variable selection). Why is it important? How can data management procedures such as missing data handling make it worse?</li>
<li>Provide a simple example of how an experimental design can help answer a question about behavior. How does experimental data contrast with observational data?</li>
<li>Is mean imputation of missing data acceptable practice? Why or why not?</li>
<li>What is an outlier? Explain how you might screen for outliers and what would you do if you found them in your dataset. Also, explain what an inlier is and how you might screen for them and what would you do if you found them in your dataset</li>
<li>How do you handle missing data? What imputation techniques do you recommend?</li>
<li>You have data on the durations of calls to a call center. Generate a plan for how you would code and analyze these data. Explain a plausible scenario for what the distribution of these durations might look like. How could you test, even graphically, whether your expectations are borne out?</li>
<li>Explain likely differences between administrative datasets and datasets gathered from experimental studies. What are likely problems encountered with administrative data? How do experimental methods help alleviate these problems? What problem do they bring?</li>
<li>You are compiling a report for user content uploaded every month and notice a spike in uploads in October. In particular, a spike in picture uploads. What might you think is the cause of this, and how would you test it?</li>
<li>You’re about to get on a plane to Seattle. You want to know if you should bring an umbrella. You call 3 random friends of yours who live there and ask each independently if it’s raining. Each of your friends has a 2/3 chance of telling you the truth and a 1/3 chance of messing with you by lying. All 3 friends tell you that “Yes” it is raining. What is the probability that it’s actually raining in Seattle?</li>
<li>There’s one box - has 12 black and 12 red cards, 2nd box has 24 black and 24 red; if you want to draw 2 cards at random from one of the 2 boxes, which box has the higher probability of getting the same color? Can you tell intuitively why the 2nd box has a higher probability</li>
<li>What is: lift, KPI, robustness, model fitting, design of experiments, 80/20 rule?</li>
<li>Define: quality assurance, six sigma.<br /></li>
<li>Give examples of data that does not have a Gaussian distribution, nor log-normal.<br /></li>
<li>What is root cause analysis? How to identify a cause vs. a correlation? Give examples</li>
<li>Give an example where the median is a better measure than the mean</li>
<li>Given two fair dices, what is the probability of getting scores that sum to 4? to 8?</li>
<li>What is the Law of Large Numbers?</li>
<li>How do you calculate needed sample size?</li>
<li>When you sample, what bias are you inflicting?</li>
<li>How do you control for biases?</li>
<li>What are confounding variables?</li>
<li>What is A/B testing?<br /></li>
<li>An HIV test has a sensitivity of 99.7% and a specificity of 98.5%. A subject from a population of prevalence 0.1% receives a positive test result. What is the precision of the test (i.e the probability he is HIV positive)?</li>
<li>Infection rates at a hospital above a 1 infection per 100 person days at risk are considered high. An hospital had 10 infections over the last 1787 person days at risk. Give the p-value of the correct one-sided test of whether the hospital is below the standard</li>
<li>You roll a biased coin (p(head)=0.8) five times. What’s the probability of getting three or more heads?</li>
<li>A random variable X is normal with mean 1020 and standard deviation 50. Calculate P(X&gt;1200)</li>
<li>Consider the number of people that show up at a bus station is Poisson with mean 2.5/h. What is the probability that at most three people show up in a four hour period?</li>
<li>You are running for office and your pollster polled hundred people. Sixty of them claimed they will vote for you. Can you relax?</li>
<li>Geiger counter records 100 radioactive decays in 5 minutes. Find an approximate 95% interval for the number of decays per hour.</li>
<li>The homicide rate in Scotland fell last year to 99 from 115 the year before. Is this reported change really networthy?</li>
<li>Consider influenza epidemics for two parent heterosexual families. Suppose that the probability is 17% that at least one of the parents has contracted the disease. The probability that the father has contracted influenza is 12% while the probability that both the mother and father have contracted the disease is 6%. What is the probability that the mother has contracted influenza?</li>
<li>Suppose that diastolic blood pressures (DBPs) for men aged 35-44 are normally distributed with a mean of 80 (mm Hg) and a standard deviation of 10. About what is the probability that a random 35-44 year old has a DBP less than 70?</li>
<li>In a population of interest, a sample of 9 men yielded a sample average brain volume of 1,100cc and a standard deviation of 30cc. What is a 95% Student’s T confidence interval for the mean brain volume in this new population?</li>
<li>A diet pill is given to 9 subjects over six weeks. The average difference in weight (follow up - baseline) is -2 pounds. What would the standard deviation of the difference in weight have to be for the upper endpoint of the 95% T confidence interval to touch 0?</li>
<li>In a study of emergency room waiting times, investigators consider a new and the standard triage systems. To test the systems, administrators selected 20 nights and randomly assigned the new triage system to be used on 10 nights and the standard system on the remaining 10 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 3 hours with a variance of 0.60 while the average MWT for the old system was 5 hours with a variance of 0.68. Consider the 95% confidence interval estimate for the differences of the mean MWT associated with the new system. Assume a constant variance. What is the interval? Subtract in this order (New System - Old System).</li>
<li>To further test the hospital triage system, administrators selected 200 nights and randomly assigned a new triage system to be used on 100 nights and a standard system on the remaining 100 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 4 hours with a standard deviation of 0.5 hours while the average MWT for the old system was 6 hours with a standard deviation of 2 hours. Consider the hypothesis of a decrease in the mean MWT associated with the new treatment. What does the 95% independent group confidence interval with unequal variances suggest vis a vis this hypothesis? (Because there’s so many observations per group, just use the Z quantile instead of the T.)</li>
</ol>
<hr />
<div id="process-miscellaneous" class="section level3">
<h3>Process &amp; Miscellaneous</h3>
<ol style="list-style-type: decimal">
<li>How to optimize algorithms? (parallel processing and/or faster algorithms). Provide examples for both</li>
<li>Examples of NoSQL architecture</li>
<li>Provide examples of machine-to-machine communications</li>
<li>Compare R and Python</li>
<li>Is it better to have 100 small hash tables or one big hash table, in memory, in terms of access speed (assuming both fit within RAM)? What do you think about in-database analytics?</li>
<li>What is star schema? Lookup tables?</li>
<li>What is the life cycle of a data science project ?</li>
<li>How to efficiently scrape web data, or collect tons of tweets?</li>
<li>How to clean data?</li>
<li>How frequently an algorithm must be updated?<br /></li>
<li>What is POC (proof of concept)?</li>
<li>Explain Tufte’s concept of “chart junk”</li>
<li>How would you come up with a solution to identify plagiarism?</li>
<li>How to detect individual paid accounts shared by multiple users?</li>
<li>Is it better to spend 5 days developing a 90% accurate solution, or 10 days for 100% accuracy? Depends on the context?</li>
<li>What is your definition of big data?</li>
<li>Explain the difference between “long” and “wide” format data. Why would you use one or the other?</li>
<li>Do you know a few “rules of thumb” used in statistical or computer science? Or in business analytics?</li>
<li>Name a few famous API’s (for instance GoogleSearch)</li>
<li>Give examples of bad and good visualizations</li>
</ol>
<hr />
</div>
</div>
<div id="answers" class="section level2">
<h2>Answers</h2>
<hr />
<div id="machine-learning-mathematics-1" class="section level3">
<h3>Machine Learning &amp; Mathematics</h3>
<hr />
<div id="what-is-cross-validation-how-to-do-it-right" class="section level4">
<h4>1. What is cross-validation? How to do it right?</h4>
<p>It’s a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set. Mainly used in settings where the goal is prediction and one wants to estimate how accurately a model will perform in practice. The goal of cross-validation is to define a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting, and get an insight on how the model will generalize to an independent data set.</p>
<p>Examples: leave-one-out cross validation, K-fold cross validation</p>
<p>How to do it right?</p>
<ul>
<li>the training and validation data sets have to be drawn from the same population</li>
<li>predicting stock prices: trained for a certain 5-year period, it’s unrealistic to treat the subsequent 5-year a draw from the same population</li>
<li>common mistake: for instance the step of choosing the kernel parameters of a SVM should be cross-validated as well</li>
</ul>
<p><em>Bias-variance trade-off for k-fold cross validation</em>:</p>
<p>Leave-one-out cross-validation: gives approximately unbiased estimates of the test error since each training set contains almost the entire data set (<span class="math">\(n-1\)</span> observations).</p>
<p>But: we average the outputs of n fitted models, each of which is trained on an almost identical set of observations hence the outputs are highly correlated. Since the variance of a mean of quantities increases when correlation of these quantities increase, the test error estimate from a LOOCV has higher variance than the one obtained with k-fold cross validation</p>
<p>Typically, we choose <span class="math">\(k=5\)</span> or <span class="math">\(k=10\)</span>, as these values have been shown empirically to yield test error estimates that suffer neither from excessively high bias nor high variance.</p>
<hr />
</div>
<div id="is-it-better-to-design-robust-or-accurate-algorithms" class="section level4">
<h4>2. Is it better to design robust or accurate algorithms?</h4>
<ul>
<li>The ultimate goal is to design systems with good generalization capacity, that is, systems that correctly identify patterns in data instances not seen before</li>
<li>The generalization performance of a learning system strongly depends on the complexity of the model assumed</li>
<li>If the model is too simple, the system can only capture the actual data regularities in a rough manner. In this case, the system has poor generalization properties and is said to suffer from underfitting</li>
<li>By contrast, when the model is too complex, the system can identify accidental patterns in the training data that need not be present in the test set. These spurious patterns can be the result of random fluctuations or of measurement errors during the data collection process. In this case, the generalization capacity of the learning system is also poor. The learning system is said to be affected by overfitting</li>
<li>Spurious patterns, which are only present by accident in the data, tend to have complex forms. This is the idea behind the principle of Occam’s razor for avoiding overfitting: simpler models are preferred if more complex models do not significantly improve the quality of the description for the observations</li>
<li>Quick response: Occam’s Razor. It depends on the learning task. Choose the right balance</li>
<li>Ensemble learning can help balancing bias/variance (several weak learners together = strong learner)</li>
</ul>
<hr />
</div>
<div id="how-to-defineselect-metrics" class="section level4">
<h4>3. How to define/select metrics?</h4>
<ul>
<li>Type of task: regression? Classification?</li>
<li>Business goal?<br /></li>
<li>What is the distribution of the target variable?<br /></li>
<li>What metric do we optimize for?</li>
<li>Regression: RMSE (root mean squared error), MAE (mean absolute error), WMAE(weighted mean absolute error), RMSLE (root mean squared logarithmic error)…</li>
<li>Classification: recall, AUC, accuracy, misclassification error, Cohen’s Kappa…</li>
</ul>
<p>Common metrics in regression:</p>
<ul>
<li><p>Mean Squared Error Vs Mean Absolute Error RMSE gives a relatively high weight to large errors. The RMSE is most useful when large errors are particularly undesirable.<br />The MAE is a linear score: all the individual differences are weighted equally in the average. MAE is more robust to outliers than MSE.<br /><span class="math">\(RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}\)</span><br /><span class="math">\(MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i-\hat{y}_i|\)</span></p></li>
<li><p>Root Mean Squared Logarithmic Error<br />RMSLE penalizes an under-predicted estimate greater than an over-predicted estimate (opposite to RMSE)<br /><span class="math">\(RMSLE = \sqrt{\frac{1}{n} \sum_{i=1}^n (\log(p_i + 1) - \log(a_i+1))^2 }\)</span><br />Where <span class="math">\(p_i\)</span> is the ith prediction, <span class="math">\(a_i\)</span> the ith actual response, <span class="math">\(log(b)\)</span> the natural logarithm of <span class="math">\(b\)</span>.</p></li>
<li><p>Weighted Mean Absolute Error<br />The weighted average of absolute errors. MAE and RMSE consider that each prediction provides equally precise information about the error variation, i.e. the standard variation of the error term is constant over all the predictions. Examples: recommender systems (differences between past and recent products)<br /><span class="math">\(WMAE = \frac{1}{\sum{w_i}} \sum_{i=1}^n w_i | y_i - \hat{y}_i |\)</span></p></li>
</ul>
<p>Common metrics in classification:</p>
<ul>
<li><p>Recall / Sensitivity / True positive rate:<br />High when FN low. Sensitive to unbalanced classes.<br /><span class="math">\(Sensitivity=\frac{TP}{TP+FN}\)</span></p></li>
<li><p>Precision / Positive Predictive Value<br />High when FP low. Sensitive to unbalanced classes.<br /><span class="math">\(Precision=\frac{TP}{TP+FP}\)</span></p></li>
<li><p>Specificity / True Negative Rate<br />High when FP low. Sensitive to unbalanced classes.<br /><span class="math">\(Specificity=\frac{TN}{TN+FP}\)</span></p></li>
<li><p>Accuracy<br />High when FP and FN are low. Sensitive to unbalanced classes (see <a href="https://en.wikipedia.org/wiki/Accuracy_paradox">“Accuracy paradox”</a>)<br /><span class="math">\(Accuracy=\frac{TP+TN}{TN+TP+FP+FN}\)</span></p></li>
<li><p>ROC / AUC<br />ROC is a graphical plot that illustrates the performance of a binary classifier (<span class="math">\(Sensitivity\)</span> Vs <span class="math">\(1-Specificity\)</span> or <span class="math">\(Sensitivity\)</span> Vs <span class="math">\(Specificity\)</span>). They are not sensitive to unbalanced classes.<br />AUC is the area under the ROC curve. Perfect classifier: AUC=1, fall on (0,1); 100% sensitivity (no FN) and 100% specificity (no FP)</p></li>
<li><p>Logarithmic loss<br />Punishes infinitely the deviation from the true value! It’s better to be somewhat wrong than emphatically wrong!<br /><span class="math">\(log loss = -\frac{1}{N}\sum_{i=1}^n {(y_i\log(p_i) + (1 - y_i)\log(1 - p_i))}\)</span></p></li>
<li><p>Misclassification Rate<br /><span class="math">\(Misclassification={1 \over n}\sum_i I(y_i \neq \hat y_i)\)</span></p></li>
<li><p>F1-Score<br />Used when the target variable is unbalanced. <span class="math">\(F_1Score=2\frac{Precision\times Recall}{Precision+Recall}\)</span></p></li>
</ul>
<hr />
</div>
<div id="explain-what-regularization-is-and-why-it-is-useful.-what-are-the-benefits-and-drawbacks-of-specific-methods-such-as-ridge-regression-and-lasso" class="section level4">
<h4>4. Explain what regularization is and why it is useful. What are the benefits and drawbacks of specific methods, such as ridge regression and lasso?</h4>
<ul>
<li>Used to prevent overfitting: improve the generalization of a model</li>
<li>Decreases complexity of a model</li>
<li>Introducing a regularization term to a general loss function: adding a term to the minimization problem</li>
<li>Impose Occam’s Razor in the solution</li>
</ul>
<p>Ridge regression:</p>
<ul>
<li>We use an <span class="math">\(L2\)</span> penalty when fitting the model using least squares</li>
<li>We add to the minimization problem an expression (shrinkage penalty) of the form <span class="math">\(\lambda \times \sum coefficients\)</span><br /></li>
<li><span class="math">\(\lambda\)</span>: tuning parameter; controls the bias-variance tradeoff; accessed with cross-validation<br /></li>
<li>A bit faster than the lasso<br /><span class="math">\(\hat{\beta}^{ridge} = \underset{\beta}{\operatorname{argmin}} \left\{ \sum_{i=1}^n(y_i-\beta_0-\sum_{j=1}^p x_{ij} \beta_j)^2 + \lambda \sum_{j=1}^p \beta_j^2 \right\}\)</span></li>
</ul>
<p>The Lasso:</p>
<ul>
<li>We use an <span class="math">\(L1\)</span> penalty when fitting the model using least squares<br /></li>
<li>Can force regression coefficients to be exactly: feature selection method by itself<br /><span class="math">\(\hat{\beta}^{lasso} = \underset{\beta}{\operatorname{argmin}} \left\{ \sum_{i=1}^n(y_i-\beta_0-\sum_{j=1}^p x_{ij} \beta_j)^2 + \lambda \sum_{j=1}^p ||\beta_j|| \right\}\)</span></li>
</ul>
<hr />
</div>
<div id="explain-what-a-local-optimum-is-and-why-it-is-important-in-a-specific-context-such-as-k-means-clustering.-what-are-specific-ways-of-determining-if-you-have-a-local-optimum-problem-what-can-be-done-to-avoid-local-optima" class="section level4">
<h4>5. Explain what a local optimum is and why it is important in a specific context, such as K-means clustering. What are specific ways of determining if you have a local optimum problem? What can be done to avoid local optima?</h4>
<ul>
<li>A solution that is optimal in within a neighboring set of candidate solutions</li>
<li><p>In contrast with global optimum: the optimal solution among all others</p></li>
<li><p>K-means clustering context:<br />It’s proven that the objective cost function will always decrease until a local optimum is reached.<br />Results will depend on the initial random cluster assignment</p></li>
<li><p>Determining if you have a local optimum problem:<br />Tendency of premature convergence<br />Different initialization induces different optima</p></li>
<li><p>Avoid local optima in a K-means context: repeat K-means and take the solution that has the lowest cost</p></li>
</ul>
<hr />
</div>
<div id="assume-you-need-to-generate-a-predictive-model-using-multiple-regression.-explain-how-you-intend-to-validate-this-model" class="section level4">
<h4>6. Assume you need to generate a predictive model using multiple regression. Explain how you intend to validate this model</h4>
<p>Validation using <span class="math">\(R^2\)</span>:<br />- % of variance retained by the model<br />- Issue: <span class="math">\(R^2\)</span> is always increased when adding variables<br />- <span class="math">\(R^2=\frac{RSS_tot-RSS_res}{RSS_tot}=\frac{RSS_reg}{RSS_tot}=1-\frac{RSS_res}{RSS_tot}\)</span></p>
<p>Analysis of residuals:<br />- Heteroskedasticity (relation between the variance of the model errors and the size of an independent variable’s observations)<br />- Scatter plots residuals Vs predictors<br />- Normality of errors<br />- Etc. : diagnostic plots</p>
<p>Out-of-sample evaluation: with cross-validation</p>
<hr />
</div>
<div id="explain-what-precision-and-recall-are.-how-do-they-relate-to-the-roc-curve" class="section level4">
<h4>7. Explain what precision and recall are. How do they relate to the ROC curve?</h4>
<p>See question 3. “How to define/select metrics? Do you know compound metrics?”.<br />When using Precision/Recall curves.</p>
<hr />
</div>
<div id="what-is-latent-semantic-indexing-what-is-it-used-for-what-are-the-specific-limitations-of-the-method" class="section level4">
<h4>8. What is latent semantic indexing? What is it used for? What are the specific limitations of the method?</h4>
<ul>
<li>Indexing and retrieval method that uses singular value decomposition to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text</li>
<li>Based on the principle that words that are used in the same contexts tend to have similar meanings</li>
<li>“Latent”: semantic associations between words is present not explicitly but only latently</li>
<li>For example: two synonyms may never occur in the same passage but should nonetheless have highly associated representations</li>
</ul>
<p>Used for:</p>
<ul>
<li>Learning correct word meanings</li>
<li>Subject matter comprehension</li>
<li>Information retrieval</li>
<li>Sentiment analysis (social network analysis)<br />Here’s a great <a href="http://www.ling.ohio-state.edu/~reidy/LSAtutorial.pdf">tutorial</a> on it.</li>
</ul>
<hr />
</div>
<div id="explain-what-resampling-methods-are-and-why-they-are-useful" class="section level4">
<h4>9. Explain what resampling methods are and why they are useful</h4>
<ul>
<li>repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model</li>
<li>example: repeatedly draw different samples from training data, fit a linear regression to each new sample, and then examine the extent to which the resulting fit differ</li>
<li>most common are: cross-validation and the bootstrap</li>
<li>cross-validation: random sampling with no replacement</li>
<li>bootstrap: random sampling with replacement</li>
<li>cross-validation: evaluating model performance, model selection (select the appropriate level of flexibility)</li>
<li>bootstrap: mostly used to quantify the uncertainty associated with a given estimator or statistical learning method</li>
</ul>
<hr />
</div>
<div id="what-is-principal-component-analysis-explain-the-sort-of-problems-you-would-use-pca-for.-also-explain-its-limitations-as-a-method" class="section level4">
<h4>10. What is principal component analysis? Explain the sort of problems you would use PCA for. Also explain its limitations as a method</h4>
<p>Statistical method that uses an orthogonal transformation to convert a set of observations of correlated variables into a set of values of linearly uncorrelated variables called principal components.</p>
<p>Reduce the data from <span class="math">\(n\)</span> to <span class="math">\(k\)</span> dimensions: find the <span class="math">\(k\)</span> vectors onto which to project the data so as to minimize the projection error.</p>
<p>Algorithm:<br />1) Preprocessing (standardization): PCA is sensitive to the relative scaling of the original variable<br />2) Compute covariance matrix <span class="math">\(\Sigma\)</span><br />3) Compute eigenvectors of <span class="math">\(\Sigma\)</span><br />4) Choose <span class="math">\(k\)</span> principal components so as to retain <span class="math">\(x\)</span>% of the variance (typically <span class="math">\(x=99\)</span>)</p>
<p>Applications:<br />1) Compression<br />- Reduce disk/memory needed to store data<br />- Speed up learning algorithm. Warning: mapping should be defined only on training set and then applied to test set</p>
<ol start="2" style="list-style-type: decimal">
<li>Visualization: 2 or 3 principal components, so as to summarize data</li>
</ol>
<p>Limitations:<br />- PCA is not scale invariant<br />- The directions with largest variance are assumed to be of most interest<br />- Only considers orthogonal transformations (rotations) of the original variables<br />- PCA is only based on the mean vector and covariance matrix. Some distributions (multivariate normal) are characterized by this but some are not<br />- If the variables are correlated, PCA can achieve dimension reduction. If not, PCA just orders them according to their variances</p>
<hr />
</div>
<div id="explain-what-a-false-positive-and-a-false-negative-are.-why-is-it-important-these-from-each-other-provide-examples-when-false-positives-are-more-important-than-false-negatives-false-negatives-are-more-important-than-false-positives-and-when-these-two-types-of-errors-are-equally-important" class="section level4">
<h4>11. Explain what a false positive and a false negative are. Why is it important these from each other? Provide examples when false positives are more important than false negatives, false negatives are more important than false positives and when these two types of errors are equally important</h4>
<ul>
<li><p>False positive<br />Improperly reporting the presence of a condition when it’s not in reality. Example: HIV positive test when the patient is actually HIV negative</p></li>
<li><p>False negative<br />Improperly reporting the absence of a condition when in reality it’s the case. Example: not detecting a disease when the patient has this disease.</p></li>
</ul>
<p>When false positives are more important than false negatives:<br />- In a non-contagious disease, where treatment delay doesn’t have any long-term consequences but the treatment itself is grueling<br />- HIV test: psychological impact</p>
<p>When false negatives are more important than false positives:<br />- If early treatment is important for good outcomes<br />- In quality control: a defective item passes through the cracks!<br />- Software testing: a test to catch a virus has failed</p>
<hr />
</div>
<div id="what-is-the-difference-between-supervised-learning-and-unsupervised-learning-give-concrete-examples" class="section level4">
<h4>12. What is the difference between supervised learning and unsupervised learning? Give concrete examples</h4>
<ul>
<li>Supervised learning: inferring a function from labeled training data</li>
<li>Supervised learning: predictor measurements associated with a response measurement; we wish to fit a model that relates both for better understanding the relation between them (inference) or with the aim to accurately predicting the response for future observations (prediction)</li>
<li>Supervised learning: support vector machines, neural networks, linear regression, logistic regression, extreme gradient boosting</li>
<li>Supervised learning examples: predict the price of a house based on the are, size.; churn prediction; predict the relevance of search engine results.</li>
<li>Unsupervised learning: inferring a function to describe hidden structure of unlabeled data</li>
<li>Unsupervised learning: we lack a response variable that can supervise our analysis</li>
<li>Unsupervised learning: clustering, principal component analysis, singular value decomposition; identify group of customers</li>
<li>Unsupervised learning examples: find customer segments; image segmentation; classify US senators by their voting.</li>
</ul>
<hr />
</div>
<div id="what-does-nlp-stand-for" class="section level4">
<h4>13. What does NLP stand for?</h4>
<p>“Natural language processing”!</p>
<ul>
<li>Interaction with human (natural) and computers languages<br /></li>
<li>Involves natural language understanding</li>
</ul>
<p>Major tasks:<br />- Machine translation<br />- Question answering: “what’s the capital of Canada?”<br />- Sentiment analysis: extract subjective information from a set of documents, identify trends or public opinions in the social media<br />- Information retrieval</p>
<hr />
</div>
<div id="what-are-feature-vectors" class="section level4">
<h4>14. What are feature vectors?</h4>
<ul>
<li>n-dimensional vector of numerical features that represent some object</li>
<li>term occurrences frequencies, pixels of an image etc.</li>
<li>Feature space: vector space associated with these vectors</li>
</ul>
<hr />
</div>
<div id="when-would-you-use-random-forests-vs-svm-and-why" class="section level4">
<h4>15. When would you use random forests Vs SVM and why?</h4>
<ul>
<li>In a case of a multi-class classification problem: SVM will require one-against-all method (memory intensive)</li>
<li>If one needs to know the variable importance (random forests can perform it as well)</li>
<li>If one needs to get a model fast (SVM is long to tune, need to choose the appropriate kernel and its parameters, for instance sigma and epsilon)</li>
<li>In a semi-supervised learning context (random forest and dissimilarity measure): SVM can work only in a supervised learning mode</li>
</ul>
<hr />
</div>
<div id="how-do-you-take-millions-of-users-with-100s-transactions-each-amongst-10ks-of-products-and-group-the-users-together-in-meaningful-segments" class="section level4">
<h4>16. How do you take millions of users with 100’s transactions each, amongst 10k’s of products and group the users together in meaningful segments?</h4>
<ol style="list-style-type: decimal">
<li>Some exploratory data analysis (get a first insight)</li>
</ol>
<ul>
<li>Transactions by date</li>
<li>Count of customers Vs number of items bought</li>
<li>Total items Vs total basket per customer</li>
<li>Total items Vs total basket per area</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Create new features (per customer):</li>
</ol>
<p>Counts:</p>
<ul>
<li>Total baskets (unique days)</li>
<li>Total items</li>
<li>Total spent</li>
<li>Unique product id</li>
</ul>
<p>Distributions:</p>
<ul>
<li>Items per basket<br /></li>
<li>Spent per basket<br /></li>
<li>Product id per basket<br /></li>
<li>Duration between visits<br /></li>
<li>Product preferences: proportion of items per product cat per basket</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>Too many features, dimension-reduction? PCA?</p></li>
<li>Clustering:</li>
</ol>
<ul>
<li>PCA</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Interpreting model fit</li>
</ol>
<ul>
<li>View the clustering by principal component axis pairs PC1 Vs PC2, PC2 Vs PC1.</li>
<li>Interpret each principal component regarding the linear combination it’s obtained from; example: PC1=spendy axis (proportion of baskets containing spendy items, raw counts of items and visits)</li>
</ul>
<hr />
</div>
<div id="how-do-you-know-if-one-algorithm-is-better-than-other" class="section level4">
<h4>17. How do you know if one algorithm is better than other?</h4>
<ul>
<li>In terms of performance on a given data set?</li>
<li>In terms of performance on several data sets?</li>
<li>In terms of efficiency?</li>
</ul>
<p><strong>In terms of performance on several data sets:</strong><br />- “Does learning algorithm A have a higher chance of producing a better predictor than learning algorithm B in the given context?”<br />- “Bayesian Comparison of Machine Learning Algorithms on Single and Multiple Datasets”, A. Lacoste and F. Laviolette<br />- “Statistical Comparisons of Classifiers over Multiple Data Sets”, Janez Demsar</p>
<p><strong>In terms of performance on a given data set:</strong><br />- One wants to choose between two learning algorithms<br />- Need to compare their performances and assess the statistical significance</p>
<p><em>One approach (Not preferred in the literature):</em><br />- Multiple k-fold cross validation: run CV multiple times and take the mean and sd<br />- You have: algorithm A (mean and sd) and algorithm B (mean and sd)<br />- Is the difference meaningful? (Paired t-test)</p>
<p><em>Sign-test (classification context):</em><br />Simply counts the number of times A has a better metrics than B and assumes this comes from a binomial distribution. Then we can obtain a p-value of the <span class="math">\(H_o\)</span> test: A and B are equal in terms of performance.</p>
<p><em>Wilcoxon signed rank test (classification context):</em><br />Like the sign-test, but the wins (A is better than B) are weighted and assumed coming from a symmetric distribution around a common median. Then, we obtain a p-value of the <span class="math">\(H_o\)</span> test.</p>
<p><em>Other (without hypothesis testing):</em><br />- AUC<br />- F-Score<br />- See question 3</p>
<hr />
</div>
<div id="how-do-you-test-whether-a-new-credit-risk-scoring-model-works" class="section level4">
<h4>18. How do you test whether a new credit risk scoring model works?</h4>
<ul>
<li>Test on a holdout set<br /></li>
<li>Kolmogorov-Smirnov test</li>
</ul>
<p>Kolmogorov-Smirnov test:<br />- Non-parametric test<br />- Compare a sample with a reference probability distribution or compare two samples<br />- Quantifies a distance between the empirical distribution function of the sample and the cumulative distribution function of the reference distribution<br />- Or between the empirical distribution functions of two samples<br />- Null hypothesis (two-samples test): samples are drawn from the same distribution<br />- Can be modified as a goodness of fit test<br />- In our case: cumulative percentages of good, cumulative percentages of bad</p>
<hr />
</div>
<div id="what-is-collaborative-filtering-n-grams-cosine-distance" class="section level4">
<h4>19. What is: collaborative filtering, n-grams, cosine distance?</h4>
<p><strong>Collaborative filtering:</strong><br />- Technique used by some recommender systems<br />- Filtering for information or patterns using techniques involving collaboration of multiple agents: viewpoints, data sources.<br />1. A user expresses his/her preferences by rating items (movies, CDs.)<br />2. The system matches this user’s ratings against other users’ and finds people with most similar tastes<br />3. With similar users, the system recommends items that the similar users have rated highly but not yet being rated by this user</p>
<p><strong>n-grams:</strong><br />- Contiguous sequence of n items from a given sequence of text or speech<br />- “Andrew is a talented data scientist”<br />- Bi-gram: “Andrew is”, “is a”, “a talented”.<br />- Tri-grams: “Andrew is a”, “is a talented”, “a talented data”.<br />- An n-gram model models sequences using statistical properties of n-grams; see: Shannon Game<br />- More concisely, n-gram model: <span class="math">\(P(X_i|X_{i-(n-1)}...X_{i-1})\)</span>: Markov model<br />- N-gram model: each word depends only on the <span class="math">\(n-1\)</span> last words</p>
<p>Issues:<br />- when facing infrequent n-grams<br />- solution: smooth the probability distributions by assigning non-zero probabilities to unseen words or n-grams<br />- Methods: Good-Turing, Backoff, Kneser-Kney smoothing</p>
<p><strong>Cosine distance:</strong><br />- How similar are two documents?<br />- Perfect similarity/agreement: 1<br />- No agreement : 0 (orthogonality)<br />- Measures the orientation, not magnitude</p>
<p>Given two vectors A and B representing word frequencies:<br /><span class="math">\(\text{cosine-similarity}(A,B) = \frac{\left&lt;A,B\right&gt;}{||A||\cdot||B||}\)</span></p>
<hr />
</div>
<div id="what-is-better-good-data-or-good-models-and-how-do-you-define-good-is-there-a-universal-good-model-are-there-any-models-that-are-definitely-not-so-good" class="section level4">
<h4>20. What is better: good data or good models? And how do you define “good”? Is there a universal good model? Are there any models that are definitely not so good?</h4>
<ul>
<li>Good data is definitely more important than good models<br /></li>
<li>If quality of the data wasn’t of importance, organizations wouldn’t spend so much time cleaning and preprocessing it!<br /></li>
<li>Even for scientific purpose: good data (reflected by the design of experiments) is very important</li>
</ul>
<p><strong>How do you define good?</strong><br />- good data: data relevant regarding the project/task to be handled<br />- good model: model relevant regarding the project/task<br />- good model: a model that generalizes on external data sets</p>
<p><strong>Is there a universal good model?</strong><br />- No, otherwise there wouldn’t be the overfitting problem!<br />- Algorithm can be universal but not the model<br />- Model built on a specific data set in a specific organization could be ineffective in other data set of the same organization<br />- Models have to be updated on a somewhat regular basis</p>
<p><strong>Are there any models that are definitely not so good?</strong><br />- “all models are wrong but some are useful” George E.P. Box<br />- It depends on what you want: predictive models or explanatory power<br />- If both are bad: bad model</p>
<hr />
</div>
<div id="why-is-naive-bayes-so-bad-how-would-you-improve-a-spam-detection-algorithm-that-uses-naive-bayes" class="section level4">
<h4>21. Why is naive Bayes so bad? How would you improve a spam detection algorithm that uses naive Bayes?</h4>
<ul>
<li>Naïve: the features are assumed independent/uncorrelated<br /></li>
<li>Assumption not feasible in many cases<br /></li>
<li>Improvement: decorrelate features (covariance matrix into identity matrix)</li>
</ul>
<hr />
</div>
<div id="what-are-the-drawbacks-of-linear-model-are-you-familiar-with-alternatives-lasso-ridge-regression" class="section level4">
<h4>22. What are the drawbacks of linear model? Are you familiar with alternatives (Lasso, ridge regression)?</h4>
<ul>
<li>Assumption of linearity of the errors<br /></li>
<li>Can’t be used for count outcomes, binary outcomes<br /></li>
<li>Can’t vary model flexibility: overfitting problems<br /></li>
<li>Alternatives: see question 4 about regularization</li>
</ul>
<hr />
</div>
<div id="do-you-think-50-small-decision-trees-are-better-than-a-large-one-why" class="section level4">
<h4>23. Do you think 50 small decision trees are better than a large one? Why?</h4>
<ul>
<li>Yes!<br /></li>
<li>More robust model (ensemble of weak learners that come and make a strong learner)<br /></li>
<li>Better to improve a model by taking many small steps than fewer large steps<br /></li>
<li>If one tree is erroneous, it can be auto-corrected by the following<br /></li>
<li>Less prone to overfitting</li>
</ul>
<hr />
</div>
<div id="why-is-mean-square-error-a-bad-measure-of-model-performance-what-would-you-suggest-instead" class="section level4">
<h4>24. Why is mean square error a bad measure of model performance? What would you suggest instead?</h4>
<ul>
<li>see question 3 about metrics in regression<br /></li>
<li>It puts too much emphasis on large deviations (squared)<br /></li>
<li>Alternative: mean absolute deviation</li>
</ul>
<hr />
</div>
<div id="how-can-you-prove-that-one-improvement-youve-brought-to-an-algorithm-is-really-an-improvement-over-not-doing-anything-are-you-familiar-with-ab-testing" class="section level4">
<h4>25. How can you prove that one improvement you’ve brought to an algorithm is really an improvement over not doing anything? Are you familiar with A/B testing?</h4>
<p><strong>Example with linear regression:</strong><br />- F-statistic (ANOVA)</p>
<p><span class="math">\(F=\frac{\frac{RSS_1-RSS_2}{p_2-p_1}}{\frac{RSS_2}{n-p_2}}\)</span></p>
<p><span class="math">\(p_1\)</span>: number of parameters of model 1<br /><span class="math">\(p_2\)</span>: number of parameters of model 2<br /><span class="math">\(n\)</span>: number of observations</p>
<p>Under the null hypothesis that model 2 doesn’t provide a significantly better fit than model 1, <span class="math">\(F\)</span> will have an <span class="math">\(F\)</span> distribution with <span class="math">\((p_2-p_1,n-p_2)\)</span> degrees of freedom. The null hypothesis is rejected if the <span class="math">\(F\)</span> calculated from the data is greater than the critical value of the <span class="math">\(F\)</span> distribution for some desired significance level.</p>
<p>Others: AIC/BIC (regression), cross-validation: assessing test error on a test/validation set</p>
<hr />
</div>
<div id="what-do-you-think-about-the-idea-of-injecting-noise-in-your-data-set-to-test-the-sensitivity-of-your-models" class="section level4">
<h4>26. What do you think about the idea of injecting noise in your data set to test the sensitivity of your models?</h4>
<ul>
<li>Effect would be similar to regularization: avoid overfitting<br /></li>
<li>Used to increase robustness</li>
</ul>
<hr />
</div>
<div id="do-you-know-used-data-reduction-techniques-other-than-pca-what-do-you-think-of-step-wise-regression-what-kind-of-step-wise-techniques-are-you-familiar-with" class="section level4">
<h4>27. Do you know / used data reduction techniques other than PCA? What do you think of step-wise regression? What kind of step-wise techniques are you familiar with?</h4>
<p><strong>data reduction techniques other than PCA?:</strong><br />Partial least squares: like PCR (principal component regression) but chooses the principal components in a supervised way. Gives higher weights to variables that are most strongly related to the response</p>
<p><strong>step-wise regression?</strong><br />- the choice of predictive variables are carried out using a systematic procedure<br />- Usually, it takes the form of a sequence of F-tests, t-tests, adjusted R-squared, AIC, BIC<br />- at any given step, the model is fit using unconstrained least squares<br />- can get stuck in local optima<br />- Better: Lasso</p>
<p><strong>step-wise techniques:</strong><br />- Forward-selection: begin with no variables, adding them when they improve a chosen model comparison criterion<br />- Backward-selection: begin with all the variables, removing them when it improves a chosen model comparison criterion</p>
<p><strong>Better than reduced data:</strong><br />Example 1: If all the components have a high variance: which components to discard with a guarantee that there will be no significant loss of the information?<br />Example 2 (classification):<br />- One has 2 classes; the within class variance is very high as compared to between class variance<br />- PCA might discard the very information that separates the two classes</p>
<p><strong>Better than a sample:</strong><br />- When number of variables is high relative to the number of observations</p>
<hr />
</div>
<div id="how-would-you-define-and-measure-the-predictive-power-of-a-metric" class="section level4">
<h4>28. How would you define and measure the predictive power of a metric?</h4>
<ul>
<li>Predictive power of a metric: the accuracy of a metric’s success at predicting the empirical<br /></li>
<li>They are all domain specific<br /></li>
<li>Example: in field like manufacturing, failure rates of tools are easily observable. A metric can be trained and the success can be easily measured as the deviation over time from the observed<br /></li>
<li>In information security: if the metric says that an attack is coming and one should do X. Did the recommendation stop the attack or the attack never happened?</li>
</ul>
<hr />
</div>
<div id="do-we-always-need-the-intercept-term-in-a-regression-model" class="section level4">
<h4>29. Do we always need the intercept term in a regression model?</h4>
<ul>
<li>It guarantees that the residuals have a zero mean<br /></li>
<li>It guarantees the least squares slopes estimates are unbiased<br /></li>
<li>the regression line floats up and down, by adjusting the constant, to a point where the mean of the residuals is zero</li>
</ul>
<hr />
</div>
<div id="what-are-the-assumptions-required-for-linear-regression-what-if-some-of-these-assumptions-are-violated" class="section level4">
<h4>30. What are the assumptions required for linear regression? What if some of these assumptions are violated?</h4>
<ol style="list-style-type: decimal">
<li>The data used in fitting the model is representative of the population<br /></li>
<li>The true underlying relation between <span class="math">\(x\)</span> and <span class="math">\(y\)</span> is linear<br /></li>
<li>Variance of the residuals is constant (homoscedastic, not heteroscedastic)<br /></li>
<li>The residuals are independent<br /></li>
<li>The residuals are normally distributed</li>
</ol>
<p>Predict <span class="math">\(y\)</span> from <span class="math">\(x\)</span>: 1) + 2)<br />Estimate the standard error of predictors: 1) + 2) + 3)<br />Get an unbiased estimation of <span class="math">\(y\)</span> from <span class="math">\(x\)</span>: 1) + 2) + 3) + 4)<br />Make probability statements, hypothesis testing involving slope and correlation, confidence intervals: 1) + 2) + 3) + 4) + 5)</p>
<p>Note:<br />- Common mythology: linear regression doesn’t assume anything about the distributions of <span class="math">\(x\)</span> and <span class="math">\(y\)</span><br />- It only makes assumptions about the distribution of the residuals<br />- And this is only needed for statistical tests to be valid<br />- Regression can be applied to many purposes, even if the errors are not normally distributed</p>
<hr />
</div>
<div id="what-is-collinearity-and-what-to-do-with-it-how-to-remove-multicollinearity" class="section level4">
<h4>31. What is collinearity and what to do with it? How to remove multicollinearity?</h4>
<p><strong>Collinearity/Multicollinearity:</strong><br />- In multiple regression: when two or more variables are highly correlated<br />- They provide redundant information<br />- In case of perfect multicollinearity: <span class="math">\(\beta=(X^TX)^{-1}X^Ty\)</span> doesn’t exist, the design matrix isn’t invertible<br />- It doesn’t affect the model as a whole, doesn’t bias results<br />- The standard errors of the regression coefficients of the affected variables tend to be large<br />- The test of hypothesis that the coefficient is equal to zero may lead to a failure to reject a false null hypothesis of no effect of the explanatory (Type II error)<br />- Leads to overfitting</p>
<p><strong>Remove multicollinearity:</strong><br />- Drop some of affected variables<br />- Principal component regression: gives uncorrelated predictors<br />- Combine the affected variables<br />- Ridge regression<br />- Partial least square regression</p>
<p><strong>Detection of multicollinearity:</strong><br />- Large changes in the individual coefficients when a predictor variable is added or deleted<br />- Insignificant regression coefficients for the affected predictors but a rejection of the joint<br />hypothesis that those coefficients are all zero (F-test)<br />- VIF: the ratio of variances of the coefficient when fitting the full model divided by the variance of the coefficient when fitted on its own<br />- rule of thumb: <span class="math">\(VIF&gt;5\)</span> indicates multicollinearity<br />- Correlation matrix, but correlation is a bivariate relationship whereas multicollinearity is multivariate</p>
<hr />
</div>
<div id="how-to-check-if-the-regression-model-fits-the-data-well" class="section level4">
<h4>32. How to check if the regression model fits the data well?</h4>
<p><strong>R squared/Adjusted R squared:</strong><br />- <span class="math">\(R^2=\frac{RSS_tot-RSS_res}{RSS_tot}=\frac{RSS_reg}{RSS_tot}=1-\frac{RSS_res}{RSS_tot}\)</span><br />- Describes the percentage of the total variation described by the model<br />- <span class="math">\(R^2\)</span> always increases when adding new variables: adjusted <span class="math">\(R^2\)</span> incorporates the model’s degrees of freedom</p>
<p><strong>F test:</strong><br />- Evaluate the hypothesis <span class="math">\(H_o\)</span>: all regression coefficients are equal to zero Vs <span class="math">\(H_1\)</span>: at least one doesn’t<br />- Indicates that <span class="math">\(R^2\)</span> is reliable</p>
<p><strong>RMSE:</strong><br />- Absolute measure of fit (whereas <span class="math">\(R^2\)</span> is a relative measure of fit)</p>
<hr />
</div>
<div id="what-is-a-decision-tree" class="section level4">
<h4>33. What is a decision tree?</h4>
<ol style="list-style-type: decimal">
<li>Take the entire data set as input<br /></li>
<li>Search for a split that maximizes the “separation” of the classes. A split is any test that divides the data in two (e.g. if variable2&gt;10)<br /></li>
<li>Apply the split to the input data (divide step)<br /></li>
<li>Re-apply steps 1 to 2 to the divided data<br /></li>
<li>Stop when you meet some stopping criteria<br /></li>
<li>(Optional) Clean up the tree when you went too far doing splits (called pruning)</li>
</ol>
<p>Finding a split: methods vary, from greedy search (e.g. C4.5) to randomly selecting attributes and split points (random forests)</p>
<p>Purity measure: information gain, Gini coefficient, Chi Squared values</p>
<p>Stopping criteria: methods vary from minimum size, particular confidence in prediction, purity criteria threshold</p>
<p>Pruning: reduced error pruning, out of bag error pruning (ensemble methods)</p>
<hr />
</div>
<div id="what-impurity-measures-do-you-know" class="section level4">
<h4>34. What impurity measures do you know?</h4>
<p><strong>Gini</strong><br /><span class="math">\(Gini=1-\sum_{j}p_j^2\)</span></p>
<p><strong>Information Gain/Deviance</strong><br /><span class="math">\(InformationGain=\sum_{j}p_jlog_2p_j\)</span><br />Better than Gini when <span class="math">\(p_j\)</span> are very small: multiplying very small numbers leads to rounding errors, we can instead take logs.</p>
<hr />
</div>
<div id="what-is-random-forest-why-is-it-good" class="section level4">
<h4>35. What is random forest? Why is it good?</h4>
<p><strong>Random forest? (Intuition):</strong><br />- Underlying principle: several weak learners combined provide a strong learner<br />- Builds several decision trees on bootstrapped training samples of data<br />- On each tree, each time a split is considered, a random sample of <span class="math">\(m\)</span> predictors is chosen as split candidates, out of all <span class="math">\(p\)</span> predictors<br />- Rule of thumb: at each split <span class="math">\(m=\sqrt{p}\)</span><br />- Predictions: at the majority rule</p>
<p><strong>Why is it good?</strong><br />- Very good performance (decorrelates the features)<br />- Can model non-linear class boundaries<br />- Generalization error for free: no cross-validation needed, gives an unbiased estimate of the generalization error as the trees is built<br />- Generates variable importance</p>
<hr />
</div>
<div id="how-do-we-train-a-logistic-regression-model-how-do-we-interpret-its-coefficients" class="section level4">
<h4>36. How do we train a logistic regression model? How do we interpret its coefficients?</h4>
<p><span class="math">\(\log(odds)=\log(\frac{P(y=1|x)}{P(y=0|x)})=\)</span> is a linear function of the input features</p>
<p><strong>Minimization objective/Cost function:</strong><br /><span class="math">\(J(\beta)=-\frac{1}{m}\sum_{i=1}^{m}y^{i}\log(h_\beta(x^{i}))+(1-y^{i})\log(1-h_\beta(x^{i}))\)</span><br />Where: <span class="math">\(h_{\beta}(x)=g(\beta^{T}x)\)</span> and <span class="math">\(g(z)=\frac{1}{1+e^{-z}}\)</span> (sigmoid function)<br />Intuition:<br />- if <span class="math">\(y_i=0\)</span>, <span class="math">\(J(\beta)=log(1-h_\beta(x)_i)\)</span>, will converge to <span class="math">\(\infty\)</span> as <span class="math">\(h_\beta(x)_i\)</span> becomes far from 0<br />- Converse: when <span class="math">\(y_i=1\)</span>, <span class="math">\(J(\beta)=log(h_\beta(x)_i)\)</span>, will converge to <span class="math">\(\infty\)</span> as <span class="math">\(h_\beta(x)_i\)</span> becomes far from 1</p>
<p>Interpretation of the coefficients: the increase of <span class="math">\(\log{odds}\)</span> for the increase of one unit of a predictor, given all the other predictors are fixed.</p>
<hr />
</div>
<div id="what-is-the-maximal-margin-classifier-how-this-margin-can-be-achieved" class="section level4">
<h4>37. What is the maximal margin classifier? How this margin can be achieved?</h4>
<ul>
<li>When the data can be perfectly separated using a hyperplane, there actually exists an infinite number of these hyperplanes<br /></li>
<li>Intuition: a hyperplane can usually be shifted a tiny bit up, or down, or rotated, without coming into contact with any of the observations<br /></li>
<li>Large margin classifier: choosing the hyperplance that is farthest from the training observations<br /></li>
<li>This margin can be achievec using support vectors</li>
</ul>
<hr />
</div>
<div id="what-is-a-kernel-explain-the-kernel-trick" class="section level4">
<h4>38. What is a kernel? Explain the kernel trick</h4>
<hr />
</div>
<div id="which-kernels-do-you-know-how-to-choose-a-kernel" class="section level4">
<h4>39. Which kernels do you know? How to choose a kernel?</h4>
<ul>
<li>Gaussian kernel<br /></li>
<li>Linear kernel<br /></li>
<li>Polynomial kernel<br /></li>
<li>Laplace kernel<br /></li>
<li>Esoteric kernels: string kernels, chi-square kernels<br /></li>
<li>If number of features is large (relative to number of observations): SVM with linear kernel ; e.g. text classification with lots of words, small training example<br /></li>
<li>If number of features is small, number of observations is intermediate: Gaussian kernel<br /></li>
<li>If number of features is small, number of observations is small: linear kernel</li>
</ul>
<hr />
</div>
<div id="is-it-beneficial-to-perform-dimensionality-reduction-before-fitting-an-svm-why-or-why-not" class="section level4">
<h4>40. Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?</h4>
<ul>
<li>When the number of features is large comparing to the number of observations (e.g. document-term matrix)<br /></li>
<li>SVM will perform better in this reduced space</li>
</ul>
<hr />
</div>
<div id="what-is-an-artificial-neural-network-what-is-back-propagation" class="section level4">
<h4>41. What is an Artificial Neural Network? What is back propagation?</h4>
<hr />
</div>
<div id="what-is-curse-of-dimensionality-how-does-it-affect-distance-and-similarity-measures" class="section level4">
<h4>42. What is curse of dimensionality? How does it affect distance and similarity measures?</h4>
<ul>
<li>Refers to various phenomena that arise when analyzing and organizing data in high dimensional spaces<br /></li>
<li>Common theme: when number of dimensions increases, the volume of the space increases so fast that the available data becomes sparse<br /></li>
<li>Issue with any method that requires statistical significance: the amount of data needed to support the result grows exponentially with the dimensionality<br /></li>
<li>Issue when algorithms don’t scale well on high dimensions typically when <span class="math">\(O(n^{kn})\)</span><br /></li>
<li>Everything becomes far and difficult to organize</li>
</ul>
<p><strong>Illustrative example</strong>: compare the proportion of an inscribed hypersphere with radius <span class="math">\(r\)</span> and dimension d to that of a hypercube with edges of length <span class="math">\(2r\)</span><br />- Volume of such a sphere is <span class="math">\(V_{sphere}=\frac{2r^d\pi^{d/2}}{d\Gamma(d/2)}\)</span><br />- The volume of the cube is: <span class="math">\(V_{cube}=2r^d\)</span><br />As d increases (space dimension), the volume of hypersphere becomes insignificant relative to the volume of the hypercube:<br /><span class="math">\[\lim_{d\to\infty}\frac{V_{sphere}}{V_{cube}}=\frac{\pi^{d/2}}{d2^{d-1}\Gamma(d/2)}=0\]</span><br />- Nearly all of the dimensional space is far away from the center<br />- It consists almost entirely of the corners of the hypercube, with no middle!</p>
<hr />
</div>
<div id="what-is-axb-how-to-solve-it" class="section level4">
<h4>43. What is <span class="math">\(Ax=b\)</span>? How to solve it?</h4>
<ul>
<li>A matrix equation/a system of linear equations<br /></li>
<li>calculate the inverse of <span class="math">\(A\)</span> (if non singular)</li>
<li>can be done using Gaussian elimination</li>
</ul>
<hr />
</div>
<div id="how-do-we-multiply-matrices" class="section level4">
<h4>44. How do we multiply matrices?</h4>
<ul>
<li><span class="math">\(A\in \mathbb{R}^{n\times m}\)</span> and <span class="math">\(B\in \mathbb{R}^{m\times p}\)</span><br /></li>
<li>Each entry: <span class="math">\(AB_{ij}=\sum_{k=1}^m{A_{ik}B_{kj}}\)</span></li>
</ul>
<hr />
</div>
<div id="what-is-singular-value-decomposition-what-is-an-eigenvalue-and-what-is-an-eigenvector" class="section level4">
<h4>45. What is singular value decomposition? What is an eigenvalue? And what is an eigenvector?</h4>
<hr />
</div>
<div id="whats-the-relationship-between-pca-and-svd" class="section level4">
<h4>46. What’s the relationship between PCA and SVD?</h4>
<hr />
</div>
<div id="can-you-derive-the-ordinary-least-square-regression-formula" class="section level4">
<h4>47. Can you derive the ordinary least square regression formula?</h4>
<hr />
</div>
<div id="what-is-the-difference-between-a-convex-function-and-non-convex" class="section level4">
<h4>48. What is the difference between a convex function and non-convex?</h4>
<hr />
</div>
<div id="what-is-gradient-descent-method-will-gradient-descent-methods-always-converge-to-the-same-point" class="section level4">
<h4>49. What is gradient descent method? Will gradient descent methods always converge to the same point?</h4>
<hr />
</div>
<div id="what-the-newtons-method-is" class="section level4">
<h4>50. What the Newton’s method is?</h4>
<hr />
</div>
<div id="imagine-you-have-n-pieces-of-rope-in-a-bucket.-you-reach-in-and-grab-one-end-piece-then-reach-in-and-grab-another-end-piece-and-tie-those-two-together.-what-is-the-expected-value-of-the-number-of-loops-in-the-bucket" class="section level4">
<h4>51. Imagine you have N pieces of rope in a bucket. You reach in and grab one end-piece, then reach in and grab another end-piece, and tie those two together. What is the expected value of the number of loops in the bucket?</h4>
<ul>
<li>There are <span class="math">\(n\)</span> entirely unattached pieces of rope in a bucket<br /></li>
<li>A loop: any number of rope attached in a closed chain<br /></li>
<li>Suppose the expected number of loops for <span class="math">\(n-1\)</span> pieces of rope is denoted <span class="math">\(L_{n-1}\)</span><br /></li>
<li>Consider the bucket of <span class="math">\(n\)</span> pieces of rope; there are <span class="math">\(2n\)</span> rope ends</li>
</ul>
<p>Pick an end of rope. Of the remaining <span class="math">\(2n-1\)</span> ends of rope, only one end creates a loop (the other end of the same piece of rope). There are then <span class="math">\(n-1\)</span> untied pieces of rope. The rest of the time, two separates pieces of rope are tied together and there are effectively <span class="math">\(n-1\)</span> untied pieces of rope. The recurrence is therefore:</p>
<ul>
<li><span class="math">\(L_n = \frac{1}{2n-1}+L_{n-1}\)</span></li>
</ul>
<p>Clearly, <span class="math">\(L_1=1\)</span> so:</p>
<ul>
<li><span class="math">\(L_n = \sum_{k=1}^n \frac{1}{2k-1} = H_{2n}-\frac{H_n}{2}\)</span><br /></li>
<li>Where <span class="math">\(H_k\)</span> is the <span class="math">\(kth\)</span> harmonic number<br />Since <span class="math">\(H_k \doteq \gamma+\ln k\)</span> for large-ish k, where gamma=0.57722. is the Euler-Mascheroni constant, we have:<br /></li>
<li><span class="math">\(L_n \doteq \ln(2n) - \frac{\ln(n)}{2} = \ln 2\sqrt{n}\)</span></li>
</ul>
<p>Thanks to Brian Tung.</p>
<hr />
</div>
</div>
<div id="statistics-1" class="section level3">
<h3>Statistics</h3>
<hr />
<div id="how-do-you-assess-the-statistical-significance-of-an-insight" class="section level4">
<h4>1. How do you assess the statistical significance of an insight?</h4>
<ul>
<li>is this insight just observed by chance or is it a real insight?</li>
</ul>
<p>Statistical significance can be accessed using hypothesis testing:<br />- Stating a null hypothesis which is usually the opposite of what we wish to test (classifiers A and B perform equivalently, Treatment A is equal of treatment B)<br />- Then, we choose a suitable statistical test and statistics used to reject the null hypothesis<br />- Also, we choose a critical region for the statistics to lie in that is extreme enough for the null hypothesis to be rejected (p-value)<br />- We calculate the observed test statistics from the data and check whether it lies in the critical region</p>
<p>Common tests:<br />- One sample Z test<br />- Two-sample Z test<br />- One sample t-test<br />- paired t-test<br />- Two sample pooled equal variances t-test<br />- Two sample unpooled unequal variances t-test and unequal sample sizes (Welch’s t-test)<br />- Chi-squared test for variances<br />- Chi-squared test for goodness of fit<br />- Anova (for instance: are the two regression models equals? F-test)<br />- Regression F-test (i.e: is at least one of the predictor useful in predicting the response?)</p>
<hr />
</div>
<div id="explain-what-a-long-tailed-distribution-is-and-provide-three-examples-of-relevant-phenomena-that-have-long-tails.-why-are-they-important-in-classification-and-regression-problems" class="section level4">
<h4>2. Explain what a long-tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?</h4>
<ul>
<li>In long tailed distributions, a high frequency population is followed by a low frequency population, which gradually tails off asymptotically<br /></li>
<li>Rule of thumb: majority of occurrences (more than half, and when Pareto principles applies, 80%) are accounted for by the first 20% items in the distribution<br /></li>
<li>The least frequently occurring 80% of items are more important as a proportion of the total population<br /></li>
<li>Zipf’s law, Pareto distribution, power laws</li>
</ul>
<p><em>Examples:</em><br />1) Natural language<br />- Given some corpus of natural language - The frequency of any word is inversely proportional to its rank in the frequency table<br />- The most frequent word will occur twice as often as the second most frequent, three times as often as the third most frequent…<br />- “The” accounts for 7% of all word occurrences (70000 over 1 million)<br />- “of” accounts for 3.5%, followed by “and”…<br />- Only 135 vocabulary items are needed to account for half the English corpus!</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Allocation of wealth among individuals: the larger portion of the wealth of any society is controlled by a smaller percentage of the people</p></li>
<li><p>File size distribution of Internet Traffic</p></li>
</ol>
<p>Additional: Hard disk error rates, values of oil reserves in a field (a few large fields, many small ones), sizes of sand particles, sizes of meteorites</p>
<p><em>Importance in classification and regression problems:</em><br />- Skewed distribution<br />- Which metrics to use? Accuracy paradox (classification), F-score, AUC<br />- Issue when using models that make assumptions on the linearity (linear regression): need to apply a monotone transformation on the data (logarithm, square root, sigmoid function…)<br />- Issue when sampling: your data becomes even more unbalanced! Using of stratified sampling of random sampling, SMOTE (“Synthetic Minority Over-sampling Technique”, NV Chawla) or anomaly detection approach</p>
<hr />
</div>
<div id="what-is-the-central-limit-theorem-explain-it.-why-is-it-important" class="section level4">
<h4>3. What is the Central Limit Theorem? Explain it. Why is it important?</h4>
<p>The CLT states that the arithmetic mean of a sufficiently large number of iterates of independent random variables will be approximately normally distributed regardless of the underlying distribution. i.e: the sampling distribution of the sample mean is normally distributed.<br />- Used in hypothesis testing<br />- Used for confidence intervals<br />- Random variables must be iid: independent and identically distributed<br />- Finite variance</p>
<hr />
</div>
<div id="what-is-statistical-power" class="section level4">
<h4>4. What is statistical power?</h4>
<ul>
<li>sensitivity of a binary hypothesis test</li>
<li>Probability that the test correctly rejects the null hypothesis <span class="math">\(H_0\)</span> when the alternative is true <span class="math">\(H_1\)</span></li>
<li>Ability of a test to detect an effect, if the effect actually exists</li>
<li><span class="math">\(Power= P(reject \: H_0|H_1 \: is \: true)\)</span></li>
<li>As power increases, chances of Type II error (false negative) decrease<br /></li>
<li>Used in the design of experiments, to calculate the minimum sample size required so that one can reasonably detects an effect. i.e: “how many times do I need to flip a coin to conclude it is biased?”<br /></li>
<li>Used to compare tests. Example: between a parametric and a non-parametric test of the same hypothesis</li>
</ul>
<hr />
</div>
<div id="explain-selection-bias-with-regard-to-a-dataset-not-variable-selection.-why-is-it-important-how-can-data-management-procedures-such-as-missing-data-handling-make-it-worse" class="section level4">
<h4>5. Explain selection bias (with regard to a dataset, not variable selection). Why is it important? How can data management procedures such as missing data handling make it worse?</h4>
<ul>
<li>Selection of individuals, groups or data for analysis in such a way that proper randomization is not achieved</li>
</ul>
<p>Types:<br />- Sampling bias: systematic error due to a non-random sample of a population causing some members to be less likely to be included than others<br />- Time interval: a trial may terminated early at an extreme value (ethical reasons), but the extreme value is likely to be reached by the variable with the largest variance, even if all the variables have similar means<br />- Data: “cherry picking”, when specific subsets of the data are chosen to support a conclusion (citing examples of plane crashes as evidence of airline flight being unsafe, while the far more common example of flights that complete safely)<br />- Studies: performing experiments and reporting only the most favorable results<br />- Can lead to unaccurate or even erroneous conclusions<br />- Statistical methods can generally not overcome it</p>
<p>Why data handling make it worse?<br />- Example: individuals who know or suspect that they are HIV positive are less likely to participate in HIV surveys<br />- Missing data handling will increase this effect as it’s based on most HIV negative<br />-Prevalence estimates will be unaccurate</p>
<hr />
</div>
<div id="provide-a-simple-example-of-how-an-experimental-design-can-help-answer-a-question-about-behavior.-how-does-experimental-data-contrast-with-observational-data" class="section level4">
<h4>6. Provide a simple example of how an experimental design can help answer a question about behavior. How does experimental data contrast with observational data?</h4>
<ul>
<li>You are researching the effect of music-listening on studying efficiency</li>
<li>You might divide your subjects into two groups: one would listen to music and the other (control group) wouldn’t listen anything!</li>
<li>You give them a test</li>
<li>Then, you compare grades between the two groups</li>
</ul>
<p>Differences between observational and experimental data:<br />- Observational data: measures the characteristics of a population by studying individuals in a sample, but doesn’t attempt to manipulate or influence the variables of interest<br />- Experimental data: applies a treatment to individuals and attempts to isolate the effects of the treatment on a response variable</p>
<p>Observational data: find 100 women age 30 of which 50 have been smoking a pack a day for 10 years while the other have been smoke free for 10 years. Measure lung capacity for each of the 100 women. Analyze, interpret and draw conclusions from data.</p>
<p>Experimental data: find 100 women age 20 who don’t currently smoke. Randomly assign 50 of the 100 women to the smoking treatment and the other 50 to the no smoking treatment. Those in the smoking group smoke a pack a day for 10 years while those in the control group remain smoke free for 10 years. Measure lung capacity for each of the 100 women.<br />Analyze, interpret and draw conclusions from data.</p>
<hr />
</div>
<div id="is-mean-imputation-of-missing-data-acceptable-practice-why-or-why-not" class="section level4">
<h4>7. Is mean imputation of missing data acceptable practice? Why or why not?</h4>
<ul>
<li>Bad practice in general<br /></li>
<li>If just estimating means: mean imputation preserves the mean of the observed data<br /></li>
<li>Leads to an underestimate of the standard deviation<br /></li>
<li>Distorts relationships between variables by “pulling” estimates of the correlation toward zero</li>
</ul>
<hr />
</div>
<div id="what-is-an-outlier-explain-how-you-might-screen-for-outliers-and-what-would-you-do-if-you-found-them-in-your-dataset.-also-explain-what-an-inlier-is-and-how-you-might-screen-for-them-and-what-would-you-do-if-you-found-them-in-your-dataset" class="section level4">
<h4>8. What is an outlier? Explain how you might screen for outliers and what would you do if you found them in your dataset. Also, explain what an inlier is and how you might screen for them and what would you do if you found them in your dataset</h4>
<p><em>Outliers:</em><br />- An observation point that is distant from other observations<br />- Can occur by chance in any distribution<br />- Often, they indicate measurement error or a heavy-tailed distribution<br />- Measurement error: discard them or use robust statistics<br />- Heavy-tailed distribution: high skewness, can’t use tools assuming a normal distribution<br />- Three-sigma rules (normally distributed data): 1 in 22 observations will differ by twice the standard deviation from the mean<br />- Three-sigma rules: 1 in 370 observations will differ by three times the standard deviation from the mean</p>
<p>Three-sigma rules example: in a sample of 1000 observations, the presence of up to 5 observations deviating from the mean by more than three times the standard deviation is within the range of what can be expected, being less than twice the expected number and hence within 1 standard deviation of the expected number (Poisson distribution).</p>
<p>If the nature of the distribution is known a priori, it is possible to see if the number of outliers deviate significantly from what can be expected. For a given cutoff (samples fall beyond the cutoff with probability p), the number of outliers can be approximated with a Poisson distribution with lambda=pn. Example: if one takes a normal distribution with a cutoff 3 standard deviations from the mean, p=0.3% and thus we can approximate the number of samples whose deviation exceed 3 sigmas by a Poisson with lambda=3</p>
<p><em>Identifying outliers:</em><br />- No rigid mathematical method<br />- Subjective exercise: be careful<br />- Boxplots<br />- QQ plots (sample quantiles Vs theoretical quantiles)</p>
<p><em>Handling outliers:</em><br />- Depends on the cause<br />- Retention: when the underlying model is confidently known<br />- Regression problems: only exclude points which exhibit a large degree of influence on the estimated coefficients (Cook’s distance)</p>
<p><em>Inlier:</em><br />- Observation lying within the general distribution of other observed values<br />- Doesn’t perturb the results but are non-conforming and unusual<br />- Simple example: observation recorded in the wrong unit (°F instead of °C)</p>
<p><em>Identifying inliers:</em><br />- Mahalanobi’s distance<br />- Used to calculate the distance between two random vectors<br />- Difference with Euclidean distance: accounts for correlations<br />- Discard them</p>
<hr />
</div>
<div id="how-do-you-handle-missing-data-what-imputation-techniques-do-you-recommend" class="section level4">
<h4>9. How do you handle missing data? What imputation techniques do you recommend?</h4>
<ul>
<li>If data missing at random: deletion has no bias effect, but decreases the power of the analysis by decreasing the effective sample size<br /></li>
<li>Recommended: Knn imputation, Gaussian mixture imputation</li>
</ul>
<hr />
</div>
<div id="you-have-data-on-the-durations-of-calls-to-a-call-center.-generate-a-plan-for-how-you-would-code-and-analyze-these-data.-explain-a-plausible-scenario-for-what-the-distribution-of-these-durations-might-look-like.-how-could-you-test-even-graphically-whether-your-expectations-are-borne-out" class="section level4">
<h4>10. You have data on the durations of calls to a call center. Generate a plan for how you would code and analyze these data. Explain a plausible scenario for what the distribution of these durations might look like. How could you test, even graphically, whether your expectations are borne out?</h4>
<ol style="list-style-type: decimal">
<li>Exploratory data analysis<br /></li>
</ol>
<ul>
<li>Histogram of durations<br /></li>
<li>histogram of durations per service type, per day of week, per hours of day (durations can be systematically longer from 10am to 1pm for instance), per employee…</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>Distribution: lognormal?</p></li>
<li><p>Test graphically with QQ plot: sample quantiles of <span class="math">\(\log(durations)\)</span> Vs normal quantiles</p></li>
</ol>
<hr />
</div>
<div id="explain-likely-differences-between-administrative-datasets-and-datasets-gathered-from-experimental-studies.-what-are-likely-problems-encountered-with-administrative-data-how-do-experimental-methods-help-alleviate-these-problems-what-problem-do-they-bring" class="section level4">
<h4>11. Explain likely differences between administrative datasets and datasets gathered from experimental studies. What are likely problems encountered with administrative data? How do experimental methods help alleviate these problems? What problem do they bring?</h4>
<p><em>Advantages:</em><br />- Cost<br />- Large coverage of population<br />- Captures individuals who may not respond to surveys<br />- Regularly updated, allow consistent time-series to be built-up</p>
<p><em>Disadvantages:</em><br />- Restricted to data collected for administrative purposes (limited to administrative definitions. For instance: incomes of a married couple, not individuals, which can be more useful)<br />- Lack of researcher control over content<br />- Missing or erroneous entries<br />- Quality issues (addresses may not be updated or a postal code is provided only)<br />- Data privacy issues<br />- Underdeveloped theories and methods (sampling methods…)</p>
<hr />
</div>
<div id="you-are-compiling-a-report-for-user-content-uploaded-every-month-and-notice-a-spike-in-uploads-in-october.-in-particular-a-spike-in-picture-uploads.-what-might-you-think-is-the-cause-of-this-and-how-would-you-test-it" class="section level4">
<h4>12. You are compiling a report for user content uploaded every month and notice a spike in uploads in October. In particular, a spike in picture uploads. What might you think is the cause of this, and how would you test it?</h4>
<ul>
<li>Halloween pictures?<br /></li>
<li>Look at uploads in countries that don’t observe Halloween as a sort of counter-factual analysis<br /></li>
<li>Compare uploads mean in October and uploads means with September: hypothesis testing</li>
</ul>
<hr />
</div>
<div id="youre-about-to-get-on-a-plane-to-seattle.-you-want-to-know-if-you-should-bring-an-umbrella.-you-call-3-random-friends-of-yours-who-live-there-and-ask-each-independently-if-its-raining.-each-of-your-friends-has-a-23-chance-of-telling-you-the-truth-and-a-13-chance-of-messing-with-you-by-lying.-all-3-friends-tell-you-that-yes-it-is-raining.-what-is-the-probability-that-its-actually-raining-in-seattle" class="section level4">
<h4>13. You’re about to get on a plane to Seattle. You want to know if you should bring an umbrella. You call 3 random friends of yours who live there and ask each independently if it’s raining. Each of your friends has a 2/3 chance of telling you the truth and a 1/3 chance of messing with you by lying. All 3 friends tell you that “Yes” it is raining. What is the probability that it’s actually raining in Seattle?</h4>
<ul>
<li>All say yes: all three lie or three say the truth</li>
<li><span class="math">\(P(&quot;all\:say\:the\:truth&quot;)=(\frac{2}{3})^3=\frac{8}{27}\)</span></li>
<li><span class="math">\(P(&quot;all\:lie&quot;)=(\frac{1}{3})^3=\frac{1}{27}\)</span></li>
<li><span class="math">\(P(&quot;all\:yes&quot;)=\frac{1}{27}+\frac{8}{27}=\frac{1}{3}\)</span></li>
<li>Out of these numbers, there is <span class="math">\(\frac{\frac{8}{27}}{\frac{1}{3}}=\frac{8}{9}\)</span> chance it’s actually raining</li>
</ul>
<hr />
</div>
<div id="theres-one-box---has-12-black-and-12-red-cards-2nd-box-has-24-black-and-24-red-if-you-want-to-draw-2-cards-at-random-from-one-of-the-2-boxes-which-box-has-the-higher-probability-of-getting-the-same-color-can-you-tell-intuitively-why-the-2nd-box-has-a-higher-probability" class="section level4">
<h4>14. There’s one box - has 12 black and 12 red cards, 2nd box has 24 black and 24 red; if you want to draw 2 cards at random from one of the 2 boxes, which box has the higher probability of getting the same color? Can you tell intuitively why the 2nd box has a higher probability</h4>
<ul>
<li>First select:  for both, then  and ; compare them<br /></li>
<li><span class="math">\(\frac{B}{A}=\frac{529}{517}\)</span></li>
</ul>
<hr />
</div>
<div id="what-is-lift-kpi-robustness-model-fitting-design-of-experiments-8020-rule" class="section level4">
<h4>15. What is: lift, KPI, robustness, model fitting, design of experiments, 80/20 rule?</h4>
<p><em>Lift:</em><br />It’s measure of performance of a targeting model (or a rule) at predicting or classifying cases as having an enhanced response (with respect to the population as a whole), measured against a random choice targeting model. Lift is simply: target response/average response.</p>
<p>Suppose a population has an average response rate of 5% (mailing for instance). A certain model (or rule) has identified a segment with a response rate of 20%, then lift=20/5=4</p>
<p>Typically, the modeler seeks to divide the population into quantiles, and rank the quantiles by lift. He can then consider each quantile, and by weighing the predicted response rate against the cost, he can decide to market that quantile or not.<br />“if we use the probability scores on customers, we can get 60% of the total responders we’d get mailing randomly by only mailing the top 30% of the scored customers”.</p>
<p><em>KPI:</em><br />- Key performance indicator<br />- A type of performance measurement<br />- Examples: 0 defects, 10/10 customer satisfaction<br />- Relies upon a good understanding of what is important to the organization</p>
<p>More examples:</p>
<p>Marketing &amp; Sales:<br />- New customers acquisition<br />- Customer attrition<br />- Revenue (turnover) generated by segments of the customer population<br />- Often done with a data management platform</p>
<p>IT operations:<br />- Mean time between failure<br />- Mean time to repair</p>
<p><em>Robustness:</em><br />- Statistics with good performance even if the underlying distribution is not normal<br />- Statistics that are not affected by outliers<br />- A learning algorithm that can reduce the chance of fitting noise is called robust<br />- Median is a robust measure of central tendency, while mean is not<br />- Median absolute deviation is also more robust than the standard deviation</p>
<p><em>Model fitting:</em><br />- How well a statistical model fits a set of observations<br />- Examples: AIC, <span class="math">\(R^2\)</span>, Kolmogorov-Smirnov test, Chi 2, deviance (glm)</p>
<p><em>Design of experiments:</em><br />The design of any task that aims to describe or explain the variation of information under conditions that are hypothesized to reflect the variation.<br />In its simplest form, an experiment aims at predicting the outcome by changing the preconditions, the predictors.<br />- Selection of the suitable predictors and outcomes<br />- Delivery of the experiment under statistically optimal conditions<br />- Randomization<br />- Blocking: an experiment may be conducted with the same equipment to avoid any unwanted variations in the input<br />- Replication: performing the same combination run more than once, in order to get an estimate for the amount of random error that could be part of the process<br />- Interaction: when an experiment has 3 or more variables, the situation in which the interaction of two variables on a third is not additive</p>
<p><em>80/20 rule:</em><br />- Pareto principle<br />- 80% of the effects come from 20% of the causes<br />- 80% of your sales come from 20% of your clients<br />- 80% of a company complaints come from 20% of its customers</p>
<hr />
</div>
<div id="define-quality-assurance-six-sigma." class="section level4">
<h4>16. Define: quality assurance, six sigma.</h4>
<p><em>Quality assurance:</em><br />- A way of preventing mistakes or defects in manufacturing products or when delivering services to customers<br />- In a machine learning context: anomaly detection</p>
<p><em>Six sigma:</em><br />- Set of techniques and tools for process improvement<br />- 99.99966% of products are defect-free products (3.4 per 1 million)<br />- 6 standard deviation from the process mean</p>
<hr />
</div>
<div id="give-examples-of-data-that-does-not-have-a-gaussian-distribution-nor-log-normal." class="section level4">
<h4>17. Give examples of data that does not have a Gaussian distribution, nor log-normal.</h4>
<ul>
<li>Allocation of wealth among individuals</li>
<li>Values of oil reserves among oil fields (many small ones, a small number of large ones)</li>
</ul>
<hr />
</div>
<div id="what-is-root-cause-analysis-how-to-identify-a-cause-vs.a-correlation-give-examples" class="section level4">
<h4>18. What is root cause analysis? How to identify a cause vs. a correlation? Give examples</h4>
<p><em>Root cause analysis:</em><br />- Method of problem solving used for identifying the root causes or faults of a problem<br />- A factor is considered a root cause if removal of it prevents the final undesirable event from recurring</p>
<p><em>Identify a cause vs. a correlation:</em><br />- Correlation: statistical measure that describes the size and direction of a relationship between two or more variables. A correlation between two variables doesn’t imply that the change in one variable is the cause of the change in the values of the other variable<br />- Causation: indicates that one event is the result of the occurrence of the other event; there is a causal relationship between the two events<br />- Differences between the two types of relationships are easy to identify, but establishing a cause and effect is difficult</p>
<p>Example: sleeping with one’s shoes on is strongly correlated with waking up with a headache. Correlation-implies-causation fallacy: therefore, sleeping with one’s shoes causes headache.<br />More plausible explanation: both are caused by a third factor: going to bed drunk.</p>
<p>Identify a cause Vs a correlation: use of a controlled study<br />- In medical research, one group may receive a placebo (control) while the other receives a treatment If the two groups have noticeably different outcomes, the different experiences may have caused the different outcomes</p>
<hr />
</div>
<div id="give-an-example-where-the-median-is-a-better-measure-than-the-mean" class="section level4">
<h4>19. Give an example where the median is a better measure than the mean</h4>
<p>When data is skewed</p>
<hr />
</div>
<div id="given-two-fair-dices-what-is-the-probability-of-getting-scores-that-sum-to-4-to-8" class="section level4">
<h4>20. Given two fair dices, what is the probability of getting scores that sum to 4? to 8?</h4>
<ul>
<li>Total: 36 combinations<br /></li>
<li>Of these, 3 involve a score of 4: (1,3), (3,1), (2,2)<br /></li>
<li>So: <span class="math">\(\frac{3}{36}=\frac{1}{12}\)</span><br /></li>
<li>Considering a score of 8: (2,6), (3,5), (4,4), (6,2), (5,3)<br /></li>
<li>So: <span class="math">\(\frac{5}{36}\)</span></li>
</ul>
<hr />
</div>
<div id="what-is-the-law-of-large-numbers" class="section level4">
<h4>21. What is the Law of Large Numbers?</h4>
<ul>
<li>A theorem that describes the result of performing the same experiment a large number of times</li>
<li>Forms the basis of frequency-style thinking<br /></li>
<li>It says that the sample mean, the sample variance and the sample standard deviation converge to what they are trying to estimate<br /></li>
<li>Example: roll a dice, expected value is 3.5. For a large number of experiments, the average converges to 3.5</li>
</ul>
<hr />
</div>
<div id="how-do-you-calculate-needed-sample-size" class="section level4">
<h4>22. How do you calculate needed sample size?</h4>
<p><em>Estimate a population mean:</em><br />- General formula is <span class="math">\(ME=t\times \frac{S}{\sqrt n}\)</span> or <span class="math">\(ME=z\times \frac{s}{\sqrt n}\)</span><br />- <span class="math">\(ME\)</span> is the desired margin of error<br />- <span class="math">\(t\)</span> is the t score or z score that we need to use to calculate our confidence interval<br />- <span class="math">\(s\)</span> is the standard deviation</p>
<p>Example: we would like to start a study to estimate the average internet usage of households in one week for our business plan. How many households must we randomly select to be 95% sure that the sample mean is within 1minute from the true mean of the population? A previous survey of household usage has shown a standard deviation of 6.95 minutes.</p>
<ul>
<li>Z score corresponding to a 95% interval: 1.96 (97.5%, <span class="math">\(\frac{\alpha}{2}=0.025\)</span>)</li>
<li><span class="math">\(s=6.95\)</span></li>
<li><span class="math">\(n=(\frac{z\times s}{ME})^2=(1.96\times 6.95)^2=13.62^2=186\)</span></li>
</ul>
<p><em>Estimate a proportion:</em><br />- Similar: <span class="math">\(ME=z \times \sqrt{\frac{p(1-p)}{n}}\)</span></p>
<p>Example: a professor in Harvard wants to determine the proportion of students who support gay marriage. She asks “how large a sample do I need?”<br />She wants a margin of error of less than 2.5%, she has found a previous survey which indicates a proportion of 30%.<br /><span class="math">\(n=\frac{0.3\times 0.7}{0.025^2}\)</span></p>
<hr />
</div>
<div id="when-you-sample-what-bias-are-you-inflicting" class="section level4">
<h4>23. When you sample, what bias are you inflicting?</h4>
<p><em>Selection bias:</em><br />- An online survey about computer use is likely to attract people more interested in technology than in typical</p>
<p><em>Under coverage bias:</em><br />- Sample too few observations from a segment of population</p>
<p><em>Survivorship bias:</em><br />- Observations at the end of the study are a non-random set of those present at the beginning of the investigation<br />- In finance and economics: the tendency for failed companies to be excluded from performance studies because they no longer exist</p>
<hr />
</div>
<div id="how-do-you-control-for-biases" class="section level4">
<h4>24. How do you control for biases?</h4>
<ul>
<li>Choose a representative sample, preferably by a random method<br /></li>
<li>Choose an adequate size of sample<br /></li>
<li>Identify all confounding factors if possible<br /></li>
<li>Identify sources of bias and include them as additional predictors in statistical analyses<br /></li>
<li>Use randomization: by randomly recruiting or assigning subjects in a study, all our experimental groups have an equal chance of being influenced by the same bias</li>
</ul>
<p>Notes:<br />- Randomization: in randomized control trials, research participants are assigned by chance, rather than by choice to either the experimental group or the control group.<br />- Random sampling: obtaining data that is representative of the population of interest</p>
<hr />
</div>
<div id="what-are-confounding-variables" class="section level4">
<h4>25. What are confounding variables?</h4>
<ul>
<li>Extraneous variable in a statistical model that correlates directly or inversely with both the dependent and the independent variable<br /></li>
<li>A spurious relationship is a perceived relationship between an independent variable and a dependent variable that has been estimated incorrectly<br /></li>
<li>The estimate fails to account for the confounding factor<br /></li>
<li>See Question 18 about root cause analysis</li>
</ul>
<hr />
</div>
<div id="what-is-ab-testing" class="section level4">
<h4>26. What is A/B testing?</h4>
<ul>
<li>Two-sample hypothesis testing<br /></li>
<li>Randomized experiments with two variants: A and B<br /></li>
<li>A: control; B: variation<br /></li>
<li>User-experience design: identify changes to web pages that increase clicks on a banner<br /></li>
<li>Current website: control; NULL hypothesis<br /></li>
<li>New version: variation; alternative hypothesis</li>
</ul>
<hr />
</div>
<div id="an-hiv-test-has-a-sensitivity-of-99.7-and-a-specificity-of-98.5.-a-subject-from-a-population-of-prevalence-0.1-receives-a-positive-test-result.-what-is-the-precision-of-the-test-i.e-the-probability-he-is-hiv-positive" class="section level4">
<h4>27. An HIV test has a sensitivity of 99.7% and a specificity of 98.5%. A subject from a population of prevalence 0.1% receives a positive test result. What is the precision of the test (i.e the probability he is HIV positive)?</h4>
<p>Bayes rule: <span class="math">\(P(Actu_+|Pred_+)=\frac{P(Pred_+|Actu_+)\times P(Actu_+)}{P(Pred_+|Actu_+)\times P(Actu_+)+P(Pred_+|Actu_-)P(Actu_-)}\)</span></p>
<p>We have: <span class="math">\(\frac{sensitivity\times prevalence}{sensitivity\times prevalence + (1-specificity)\times (1-prevalence)}=\frac{0.997\times 0.001}{0.997\times 0.001 + 0.15\times 0.999}=0.62\)</span></p>
<hr />
</div>
<div id="infection-rates-at-a-hospital-above-a-1-infection-per-100-person-days-at-risk-are-considered-high.-an-hospital-had-10-infections-over-the-last-1787-person-days-at-risk.-give-the-p-value-of-the-correct-one-sided-test-of-whether-the-hospital-is-below-the-standard" class="section level4">
<h4>28. Infection rates at a hospital above a 1 infection per 100 person days at risk are considered high. An hospital had 10 infections over the last 1787 person days at risk. Give the p-value of the correct one-sided test of whether the hospital is below the standard</h4>
<p>One-sided test, assume a Poisson distribution<br />Ho: lambda=0.01 ; H1:lambda&gt;0.01<br />R code:</p>
<pre class="r"><code>ppois(10,1787*0.01)</code></pre>
<pre><code>## [1] 0.03237153</code></pre>
<hr />
</div>
<div id="you-roll-a-biased-coin-phead0.8-five-times.-whats-the-probability-of-getting-three-or-more-heads" class="section level4">
<h4>29. You roll a biased coin (p(head)=0.8) five times. What’s the probability of getting three or more heads?</h4>
<ul>
<li>5 trials, p=0.8<br /><span class="math">\(P(&quot;3 \: or \: more \: heads&quot;)={3 \choose 5}\times 0.8^3 \times 0.8 \times 0.2^2+{4 \choose 1} \times 0.8^4 \times 0.2^1+{5 \choose 5}*0.8^5*0.2^0= 0.94\)</span></li>
</ul>
<hr />
</div>
<div id="a-random-variable-x-is-normal-with-mean-1020-and-standard-deviation-50.-calculate-px1200" class="section level4">
<h4>30. A random variable X is normal with mean 1020 and standard deviation 50. Calculate P(X&gt;1200)</h4>
<p><span class="math">\(X \~N(1020,50)\)</span> Our new quantile: <span class="math">\(z=\frac{1200-1020}{50}=3.6\)</span> R code:</p>
<pre class="r"><code>pnorm(3.6,lower.tail=F)   </code></pre>
<pre><code>## [1] 0.0001591086</code></pre>
<hr />
</div>
<div id="consider-the-number-of-people-that-show-up-at-a-bus-station-is-poisson-with-mean-2.5h.-what-is-the-probability-that-at-most-three-people-show-up-in-a-four-hour-period" class="section level4">
<h4>31. Consider the number of people that show up at a bus station is Poisson with mean 2.5/h. What is the probability that at most three people show up in a four hour period?</h4>
<p><span class="math">\(X \~Poisson(\lambda=2.5 \times t)\)</span><br />R code:</p>
<pre class="r"><code>ppois(3,lambda=2.5*4)   </code></pre>
<pre><code>## [1] 0.01033605</code></pre>
<hr />
</div>
<div id="you-are-running-for-office-and-your-pollster-polled-hundred-people.-56-of-them-claimed-they-will-vote-for-you.-can-you-relax" class="section level4">
<h4>32. You are running for office and your pollster polled hundred people. 56 of them claimed they will vote for you. Can you relax?</h4>
<p>Quick:<br />- Intervals take the form <span class="math">\(p \pm z \times \sqrt{\frac{1}{n} \times p \times (1-p)}\)</span><br />- We know that <span class="math">\(p(1-p)\)</span> is maximized at <span class="math">\(\frac{1}{2}\)</span> and <span class="math">\(z=1.96\)</span> is the relevant quantile for a 95% confidence interval<br />- So: <span class="math">\(p \pm \frac{1}{\sqrt{n}}\)</span> is a quick estimate for <span class="math">\(p\)</span><br />- Here: <span class="math">\(\frac {1}{\sqrt{100}}=0.1\)</span> so 95% of the intervals would be <span class="math">\([46,66]\)</span><br />- It’s not enough!</p>
<hr />
</div>
<div id="geiger-counter-records-100-radioactive-decays-in-5-minutes.-find-an-approximate-95-interval-for-the-number-of-decays-per-hour." class="section level4">
<h4>33. Geiger counter records 100 radioactive decays in 5 minutes. Find an approximate 95% interval for the number of decays per hour.</h4>
<ul>
<li>Start by finding a 95% interval for radioactive decay in a 5 minutes period<br /></li>
<li>The estimated standard deviation is <span class="math">\(\sqrt{100}=10\)</span><br /></li>
<li>So the interval is <span class="math">\(\hat{\lambda} \pm 1.96 \times 10=100 \pm 19.6\)</span><br /></li>
<li>So, per hour: <span class="math">\([964.8,1435.2]\)</span></li>
</ul>
<hr />
</div>
<div id="the-homicide-rate-in-scotland-fell-last-year-to-99-from-115-the-year-before.-is-this-reported-change-really-networthy" class="section level4">
<h4>34. The homicide rate in Scotland fell last year to 99 from 115 the year before. Is this reported change really networthy?</h4>
<ul>
<li>Consider the homicides as independent; a Poisson distribution can be a reasonable model<br /></li>
<li>95% interval for the true homicide rate is <span class="math">\(115 \pm 2\times \sqrt{115}= 115 \pm 22= [94,137]\)</span><br /></li>
<li>It’s not reasonable to conclude that there has been a reduction in the true rate</li>
</ul>
<hr />
</div>
<div id="consider-influenza-epidemics-for-two-parent-heterosexual-families.-suppose-that-the-probability-is-17-that-at-least-one-of-the-parents-has-contracted-the-disease.-the-probability-that-the-father-has-contracted-influenza-is-12-while-the-probability-that-both-the-mother-and-father-have-contracted-the-disease-is-6.-what-is-the-probability-that-the-mother-has-contracted-influenza" class="section level4">
<h4>35. Consider influenza epidemics for two parent heterosexual families. Suppose that the probability is 17% that at least one of the parents has contracted the disease. The probability that the father has contracted influenza is 12% while the probability that both the mother and father have contracted the disease is 6%. What is the probability that the mother has contracted influenza?</h4>
<ul>
<li><span class="math">\(P(&quot;Mother \: or \: Father&quot;)=P(&quot;Mother&quot;)+P(&quot;Father&quot;)-P(&quot;Mother \: and \: Father&quot;)\)</span></li>
<li>Hence: <span class="math">\(P(&quot;Mother&quot;)=0.17+0.06-0.12=0.11\)</span></li>
</ul>
<hr />
</div>
<div id="suppose-that-diastolic-blood-pressures-dbps-for-men-aged-35-44-are-normally-distributed-with-a-mean-of-80-mm-hg-and-a-standard-deviation-of-10.-about-what-is-the-probability-that-a-random-35-44-year-old-has-a-dbp-less-than-70" class="section level4">
<h4>36. Suppose that diastolic blood pressures (DBPs) for men aged 35-44 are normally distributed with a mean of 80 (mm Hg) and a standard deviation of 10. About what is the probability that a random 35-44 year old has a DBP less than 70?</h4>
<ul>
<li>One standard deviation below the mean: <span class="math">\(\frac {32}{2}=16%\)</span></li>
</ul>
<hr />
</div>
<div id="in-a-population-of-interest-a-sample-of-9-men-yielded-a-sample-average-brain-volume-of-1100cc-and-a-standard-deviation-of-30cc.-what-is-a-95-students-t-confidence-interval-for-the-mean-brain-volume-in-this-new-population" class="section level4">
<h4>37. In a population of interest, a sample of 9 men yielded a sample average brain volume of 1,100cc and a standard deviation of 30cc. What is a 95% Student’s T confidence interval for the mean brain volume in this new population?</h4>
<ul>
<li>Standard error of the mean: <span class="math">\(\frac{30}{\sqrt{9}}=10\)</span><br /></li>
<li>Relevant t quantile: 97.5%<br />R code:</li>
</ul>
<pre class="r"><code>1100+c(-1,1)*qt(0.975,df=9-1)*10   </code></pre>
<pre><code>## [1] 1076.94 1123.06</code></pre>
<hr />
</div>
<div id="a-diet-pill-is-given-to-9-subjects-over-six-weeks.-the-average-difference-in-weight-follow-up---baseline-is--2-pounds.-what-would-the-standard-deviation-of-the-difference-in-weight-have-to-be-for-the-upper-endpoint-of-the-95-t-confidence-interval-to-touch-0" class="section level4">
<h4>38. A diet pill is given to 9 subjects over six weeks. The average difference in weight (follow up - baseline) is -2 pounds. What would the standard deviation of the difference in weight have to be for the upper endpoint of the 95% T confidence interval to touch 0?</h4>
<ul>
<li>find <span class="math">\(\sigma=2 \times \frac {\sqrt{9}}{t_{97.5}}\)</span></li>
<li>R code:</li>
</ul>
<pre class="r"><code>2*3/qt(0.975,df=8)   </code></pre>
<pre><code>## [1] 2.601903</code></pre>
<hr />
</div>
<div id="in-a-study-of-emergency-room-waiting-times-investigators-consider-a-new-and-the-standard-triage-systems.-to-test-the-systems-administrators-selected-20-nights-and-randomly-assigned-the-new-triage-system-to-be-used-on-10-nights-and-the-standard-system-on-the-remaining-10-nights.-they-calculated-the-nightly-median-waiting-time-mwt-to-see-a-physician.-the-average-mwt-for-the-new-system-was-3-hours-with-a-variance-of-0.60-while-the-average-mwt-for-the-old-system-was-5-hours-with-a-variance-of-0.68.-consider-the-95-confidence-interval-estimate-for-the-differences-of-the-mean-mwt-associated-with-the-new-system.-assume-a-constant-variance.-what-is-the-interval-subtract-in-this-order-new-system---old-system." class="section level4">
<h4>39. In a study of emergency room waiting times, investigators consider a new and the standard triage systems. To test the systems, administrators selected 20 nights and randomly assigned the new triage system to be used on 10 nights and the standard system on the remaining 10 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 3 hours with a variance of 0.60 while the average MWT for the old system was 5 hours with a variance of 0.68. Consider the 95% confidence interval estimate for the differences of the mean MWT associated with the new system. Assume a constant variance. What is the interval? Subtract in this order (New System - Old System).</h4>
<p>t confidence interval for the difference of the means assuming equal variances:<br /><span class="math">\((new-old) \pm t' \times sp \times \sqrt{(\frac{1}{n_1})^2+(\frac{1}{n_2})^2}\)</span></p>
<ul>
<li>t’: 97.5% quantile, with 20+10-2=28 degrees of freedom: 2.1</li>
<li><span class="math">\(sp\)</span>: pooled variance, <span class="math">\(\sqrt{\frac{0.6^2 \times 9 + 0.68^2 \times 9}{10+10-2}}=0.8\)</span></li>
<li><span class="math">\(\sqrt{1/10+1/10}=0.44\)</span></li>
<li>We get <span class="math">\([-2.75,-1.25]\)</span></li>
</ul>
<hr />
</div>
<div id="to-further-test-the-hospital-triage-system-administrators-selected-200-nights-and-randomly-assigned-a-new-triage-system-to-be-used-on-100-nights-and-a-standard-system-on-the-remaining-100-nights.-they-calculated-the-nightly-median-waiting-time-mwt-to-see-a-physician.-the-average-mwt-for-the-new-system-was-4-hours-with-a-standard-deviation-of-0.5-hours-while-the-average-mwt-for-the-old-system-was-6-hours-with-a-standard-deviation-of-2-hours.-consider-the-hypothesis-of-a-decrease-in-the-mean-mwt-associated-with-the-new-treatment.-what-does-the-95-independent-group-confidence-interval-with-unequal-variances-suggest-vis-a-vis-this-hypothesis-because-theres-so-many-observations-per-group-just-use-the-z-quantile-instead-of-the-t." class="section level4">
<h4>40. To further test the hospital triage system, administrators selected 200 nights and randomly assigned a new triage system to be used on 100 nights and a standard system on the remaining 100 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 4 hours with a standard deviation of 0.5 hours while the average MWT for the old system was 6 hours with a standard deviation of 2 hours. Consider the hypothesis of a decrease in the mean MWT associated with the new treatment. What does the 95% independent group confidence interval with unequal variances suggest vis a vis this hypothesis? (Because there’s so many observations per group, just use the Z quantile instead of the T.)</h4>
<ul>
<li><span class="math">\(Z\)</span> confidence interval for the differences of the means assuming unequal variances: <span class="math">\((new-old) \pm z' \times sp \times \sqrt{(\frac{1}{n_1})^2+(\frac{1}{n_2})^2}\)</span></li>
<li><span class="math">\(Z_{97.5}\)</span> quantile</li>
<li><span class="math">\(sp\)</span>: pooled variance, <span class="math">\(\sqrt{\frac{0.5^2 \times 99 + 2^2 \times 99}{(100+100-2)}}=1.458\)</span></li>
<li>we get: <span class="math">\([1.6,2.4]\)</span></li>
</ul>
<hr />
</div>
</div>
<div id="process-miscellaneous-1" class="section level3">
<h3>Process &amp; Miscellaneous</h3>
<hr />
<div id="how-to-optimize-algorithms-parallel-processing-andor-faster-algorithms.-provide-examples-for-both" class="section level4">
<h4>1. How to optimize algorithms? (parallel processing and/or faster algorithms). Provide examples for both</h4>
<p>“Premature optimization is the root of all evil”; Donald Knuth</p>
<p>Parallel processing: for instance in R with a single machine.<br />- doParallel and foreach package<br />- doParallel: parallel backend, will select n-cores of the machine<br />- for each: assign tasks for each core<br />- using Hadoop on a single node<br />- using Hadoop on multi-node</p>
<p>Faster algorithm:<br />- In computer science: Pareto principle; 90% of the execution time is spent executing 10% of the code<br />- Data structure: affect performance<br />- Caching: avoid unnecessary work<br />- Improve source code level<br />For instance: on early C compilers, WHILE(something) was slower than FOR(;;), because WHILE evaluated “something” and then had a conditional jump which tested if it was true while FOR had unconditional jump.</p>
<hr />
</div>
<div id="examples-of-nosql-architecture" class="section level4">
<h4>2. Examples of NoSQL architecture</h4>
<ul>
<li>Key-value: in a key-value NoSQL database, all of the data within consists of an indexed key and a value. Cassandra, DynamoDB<br /></li>
<li>Column-based: designed for storing data tables as sections of columns of data rather than as rows of data. HBase, SAP HANA<br /></li>
<li>Document Database: map a key to some document that contains structured information. The key is used to retrieve the document. MongoDB, CouchDB<br /></li>
<li>Graph Database: designed for data whose relations are well-represented as a graph and has elements which are interconnected, with an undetermined number of relations between them. Polyglot Neo4J</li>
</ul>
<hr />
</div>
<div id="provide-examples-of-machine-to-machine-communications" class="section level4">
<h4>3. Provide examples of machine-to-machine communications</h4>
<p>Telemedicine<br />- Heart patients wear specialized monitor which gather information regarding heart state<br />- The collected data is sent to an electronic implanted device which sends back electric shocks to the patient for correcting incorrect rhythms</p>
<p>Product restocking<br />- Vending machines are capable of messaging the distributor whenever an item is running out of stock</p>
<hr />
</div>
<div id="compare-r-and-python" class="section level4">
<h4>4. Compare R and Python</h4>
<p><em>R</em><br />- Focuses on better, user friendly data analysis, statistics and graphical models<br />- The closer you are to statistics, data science and research, the more you might prefer R<br />- Statistical models can be written with only a few lines in R<br />- The same piece of functionality can be written in several ways in R<br />- Mainly used for standalone computing or analysis on individual servers<br />- Large number of packages, for anything!</p>
<p><em>Python</em><br />- Used by programmers that want to delve into data science<br />- The closer you are working in an engineering environment, the more you might prefer Python<br />- Coding and debugging is easier mainly because of the nice syntax<br />- Any piece of functionality is always written the same way in Python<br />- When data analysis needs to be implemented with web apps<br />- Good tool to implement algorithms for production use</p>
<hr />
</div>
<div id="is-it-better-to-have-100-small-hash-tables-or-one-big-hash-table-in-memory-in-terms-of-access-speed-assuming-both-fit-within-ram-what-do-you-think-about-in-database-analytics" class="section level4">
<h4>5. Is it better to have 100 small hash tables or one big hash table, in memory, in terms of access speed (assuming both fit within RAM)? What do you think about in-database analytics?</h4>
<p><em>Hash tables:</em><br />- Average case <span class="math">\(O(1)\)</span> lookup time<br />- Lookup time doesn’t depend on size</p>
<p>Even in terms of memory:<br />- <span class="math">\(O(n)\)</span> memory<br />- Space scales linearly with number of elements<br />- Lots of dictionaries won’t take up significantly less space than a larger one</p>
<p><em>In-database analytics:</em><br />- Integration of data analytics in data warehousing functionality<br />- Much faster and corporate information is more secure, it doesn’t leave the enterprise data warehouse<br />Good for real-time analytics: fraud detection, credit scoring, transaction processing, pricing and margin analysis, behavioral ad targeting and recommendation engines</p>
<hr />
</div>
<div id="what-is-star-schema-lookup-tables" class="section level4">
<h4>6. What is star schema? Lookup tables?</h4>
<p>The star schema is a traditional database schema with a central (fact) table (the “observations”, with database “keys” for joining with satellite tables, and with several fields encoded as ID’s). Satellite tables map ID’s to physical name or description and can be “joined” to the central fact table using the ID fields; these tables are known as lookup tables, and are particularly useful in real-time applications, as they save a lot of memory. Sometimes star schemas involve multiple layers of summarization (summary tables, from granular to less granular) to retrieve information faster.</p>
<p><em>Lookup tables:</em><br />- Array that replace runtime computations with a simpler array indexing operation</p>
<hr />
</div>
<div id="what-is-the-life-cycle-of-a-data-science-project" class="section level4">
<h4>7. What is the life cycle of a data science project ?</h4>
<ol style="list-style-type: decimal">
<li><p>Data acquisition<br />Acquiring data from both internal and external sources, including social media or web scraping. In a steady state, data extraction and routines should be in place, and new sources, once identified would be acquired following the established processes</p></li>
<li><p>Data preparation<br />Also called data wrangling: cleaning the data and shaping it into a suitable form for later analyses. Involves exploratory data analysis and feature extraction.</p></li>
<li><p>Hypothesis &amp; modelling<br />Like in data mining but not with samples, with all the data instead. Applying machine learning techniques to all the data. A key sub-step: model selection. This involves preparing a training set for model candidates, and validation and test sets for comparing model performances, selecting the best performing model, gauging model accuracy and preventing overfitting</p></li>
<li><p>Evaluation &amp; interpretation</p></li>
</ol>
<p>Steps 2 to 4 are repeated a number of times as needed; as the understanding of data and business becomes clearer and results from initial models and hypotheses are evaluated, further tweaks are performed. These may sometimes include step5 and be performed in a pre-production.</p>
<ol start="5" style="list-style-type: decimal">
<li><p>Deployment</p></li>
<li><p>Operations<br />Regular maintenance and operations. Includes performance tests to measure model performance, and can alert when performance goes beyond a certain acceptable threshold</p></li>
<li><p>Optimization<br />Can be triggered by failing performance, or due to the need to add new data sources and retraining the model or even to deploy new versions of an improved model</p></li>
</ol>
<p>Note: with increasing maturity and well-defined project goals, pre-defined performance can help evaluate feasibility of the data science project early enough in the data-science life cycle. This early comparison helps the team refine hypothesis, discard the project if non-viable, change approaches.</p>
<hr />
</div>
<div id="how-to-efficiently-scrape-web-data-or-collect-tons-of-tweets" class="section level4">
<h4>8. How to efficiently scrape web data, or collect tons of tweets?</h4>
<ul>
<li>Python example<br /></li>
<li>Requesting and fetching the webpage into the code: httplib2 module<br /></li>
<li>Parsing the content and getting the necessary info: BeautifulSoup from bs4 package<br /></li>
<li>Twitter API: the Python wrapper for performing API requests. It handles all the OAuth and API queries in a single Python interface<br /></li>
<li>MongoDB as the database<br /></li>
<li>PyMongo: the Python wrapper for interacting with the MongoDB database<br /></li>
<li>Cronjobs: a time based scheduler in order to run scripts at specific intervals; allows to bypass the “rate limit exceed” error</li>
</ul>
<hr />
</div>
<div id="how-to-clean-data" class="section level4">
<h4>9. How to clean data?</h4>
<ol style="list-style-type: decimal">
<li>First: detect anomalies and contradictions<br />Common issues:<br /></li>
</ol>
<ul>
<li>Tidy data: (Hadley Wickam paper)<br /><em>column names are values, not names, e.g. &lt;15-25, &gt;26-45…<br /></em>multiple variables are stored in one column, e.g. m1534 (male of 15-34 years’ old age)<br /><em>variables are stored in both rows and columns, e.g. tmax, tmin in the same column<br /></em>multiple types of observational units are stored in the same table. e.g, song dataset and rank dataset in the same table<br />*a single observational unit is stored in multiple tables (can be combined)<br /></li>
<li>Data-Type constraints: values in a particular column must be of a particular type: integer, numeric, factor, boolean<br /></li>
<li>Range constraints: number or dates fall within a certain range. They have minimum/maximum permissible values<br /></li>
<li>Mandatory constraints: certain columns can’t be empty<br /></li>
<li>Unique constraints: a field must be unique across a dataset: a same person must have a unique SS number<br /></li>
<li>Set-membership constraints: the values for a columns must come from a set of discrete values or codes: a gender must be female, male<br /></li>
<li>Regular expression patterns: for example, phone number may be required to have the pattern: (999)999-9999<br /></li>
<li>Misspellings<br /></li>
<li>Missing values<br /></li>
<li>Outliers<br /></li>
<li>Cross-field validation: certain conditions that utilize multiple fields must hold. For instance, in laboratory medicine: the sum of the different white blood cell must equal to zero (they are all percentages). In hospital database, a patient’s date or discharge can’t be earlier than the admission date</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Clean the data using:<br /></li>
</ol>
<ul>
<li>Regular expressions: misspellings, regular expression patterns<br /></li>
<li>KNN-impute and other missing values imputing methods<br /></li>
<li>Coercing: data-type constraints<br /></li>
<li>Melting: tidy data issues<br /></li>
<li>Date/time parsing<br /></li>
<li>Removing observations</li>
</ul>
<hr />
</div>
<div id="how-frequently-an-algorithm-must-be-updated" class="section level4">
<h4>10. How frequently an algorithm must be updated?</h4>
<p>You want to update an algorithm when:<br />- You want the model to evolve as data streams through infrastructure<br />- The underlying data source is changing<br />- Example: a retail store model that remains accurate as the business grows<br />- Dealing with non-stationarity</p>
<p>Some options:<br />- Incremental algorithms: the model is updated every time it sees a new training example<br />Note: simple, you always have an up-to-date model but you can’t incorporate data to different degrees.<br />Sometimes mandatory: when data must be discarded once seen (privacy)<br />- Periodic re-training in “batch” mode: simply buffer the relevant data and update the model every-so-often<br />Note: more decisions and more complex implementations</p>
<p>How frequently?<br />- Is the sacrifice worth it?<br />- Data horizon: how quickly do you need the most recent training example to be part of your model?<br />- Data obsolescence: how long does it take before data is irrelevant to the model? Are some older instances<br />more relevant than the newer ones?<br />Economics: generally, newer instances are more relevant than older ones. However, data from the same month, quarter or year of the last year can be more relevant than the same periods of the current year. In a recession period: data from previous recessions can be more relevant than newer data from different economic cycles.</p>
<hr />
</div>
<div id="what-is-poc-proof-of-concept" class="section level4">
<h4>11. What is POC (proof of concept)?</h4>
<ul>
<li>A realization of a certain method to demonstrate its feasibility<br /></li>
<li>In engineering: a rough prototype of a new idea is often constructed as a proof of concept</li>
</ul>
<hr />
</div>
<div id="explain-tuftes-concept-of-chart-junk" class="section level4">
<h4>12. Explain Tufte’s concept of “chart junk”</h4>
<p>All visuals elements in charts and graphs that are not necessary to comprehend the information represented, or that distract the viewer from this information</p>
<p>Examples of unnecessary elements include:<br />- Unnecessary text<br />- Heavy or dark grid lines<br />- Ornamented chart axes<br />- Pictures<br />- Background<br />- Unnecessary dimensions<br />- Elements depicted out of scale to one another<br />- 3-D simulations in line or bar charts</p>
<hr />
</div>
<div id="how-would-you-come-up-with-a-solution-to-identify-plagiarism" class="section level4">
<h4>13. How would you come up with a solution to identify plagiarism?</h4>
<ul>
<li>Vector space model approach<br /></li>
<li>Represent documents (the suspect and original ones) as vectors of terms<br /></li>
<li>Terms: n-grams; n=1 to as much we can (detect passage plagiarism)<br /></li>
<li>Measure the similarity between both documents<br /></li>
<li>Similarity measure: cosine distance, Jaro-Winkler, Jaccard<br /></li>
<li>Declare plagiarism at a certain threshold</li>
</ul>
<hr />
</div>
<div id="how-to-detect-individual-paid-accounts-shared-by-multiple-users" class="section level4">
<h4>14. How to detect individual paid accounts shared by multiple users?</h4>
<ul>
<li>Check geographical region: Friday morning a log in from Paris and Friday evening a log in from Tokyo<br /></li>
<li>Bandwidth consumption: if a user goes over some high limit<br /></li>
<li>Counter of live sessions: if they have 100 sessions per day (4 times per hour) that seems more than one person can do</li>
</ul>
<hr />
</div>
<div id="is-it-better-to-spend-5-days-developing-a-90-accurate-solution-or-10-days-for-100-accuracy-depends-on-the-context" class="section level4">
<h4>15. Is it better to spend 5 days developing a 90% accurate solution, or 10 days for 100% accuracy? Depends on the context?</h4>
<ul>
<li>“premature optimization is the root of all evils”<br /></li>
<li>At the beginning: quick-and-dirty model is better<br /></li>
<li>Optimization later</li>
</ul>
<p>Other answer:<br />- Depends on the context<br />- Is error acceptable? Fraud detection, quality assurance</p>
<hr />
</div>
<div id="what-is-your-definition-of-big-data" class="section level4">
<h4>16. What is your definition of big data?</h4>
<p>Big data is high volume, high velocity and/or high variety information assets that require new forms of processing<br />- Volume: big data doesn’t sample, just observes and tracks what happens<br />- Velocity: big data is often available in real-time<br />- Variety: big data comes from texts, images, audio, video…</p>
<p>Difference big data/business intelligence:<br />- Business intelligence uses descriptive statistics with data with high density information to measure things, detect trends etc.<br />- Big data uses inductive statistics (statistical inference) and concepts from non-linear system identification to infer laws (regression, classification, clustering) from large data sets with low density information to reveal relationships and dependencies or to perform prediction of outcomes or behaviors</p>
<hr />
</div>
<div id="explain-the-difference-between-long-and-wide-format-data.-why-would-you-use-one-or-the-other" class="section level4">
<h4>17. Explain the difference between “long” and “wide” format data. Why would you use one or the other?</h4>
<ul>
<li><p>Long: one column containing the values and another column listing the context of the value Fam_id year fam_inc</p></li>
<li><p>Wide: each different variable in a separate column<br />Fam_id fam_inc96 fam_inc97 fam_inc98</p></li>
</ul>
<p>Long Vs Wide:<br />- Data manipulations are much easier when data is in the wide format: summarize, filter<br />- Program requirements</p>
<hr />
</div>
<div id="do-you-know-a-few-rules-of-thumb-used-in-statistical-or-computer-science-or-in-business-analytics" class="section level4">
<h4>18. Do you know a few “rules of thumb” used in statistical or computer science? Or in business analytics?</h4>
<p><em>Pareto rule:</em><br />- 80% of the effects come from 20% of the causes<br />- 80% of the sales come from 20% of the customers</p>
<p><em>Computer science:</em> “simple and inexpensive beats complicated and expensive” - Rod Elder</p>
<p><em>Finance, rule of 72:</em><br />- Estimate the time needed for a money investment to double<br />- 100$ at a rate of 9%: 72/9=8 years</p>
<p><em>Rule of three (Economics):</em><br />- There are always three major competitors in a free market within one industry</p>
<hr />
</div>
<div id="name-a-few-famous-apis-for-instance-googlesearch" class="section level4">
<h4>19. Name a few famous API’s (for instance GoogleSearch)</h4>
<p>Google API (Google Analytics, Picasa), Twitter API (interact with Twitter functions), GitHub API, LinkedIn API (users data)…</p>
<hr />
</div>
<div id="give-examples-of-bad-and-good-visualizations" class="section level4">
<h4>20. Give examples of bad and good visualizations</h4>
<p><em>Bad visualization:</em><br />- Pie charts: difficult to make comparisons between items when area is used, especially when there are lots of items<br />- Color choice for classes: abundant use of red, orange and blue. Readers can think that the colors could mean good (blue) versus bad (orange and red) whereas these are just associated with a specific segment<br />- 3D charts: can distort perception and therefore skew data<br />- Using a solid line in a line chart: dashed and dotted lines can be distracting</p>
<p><em>Good visualization:</em><br />- Heat map with a single color: some colors stand out more than others, giving more weight to that data. A single color with varying shades show the intensity better<br />- Adding a trend line (regression line) to a scatter plot help the reader highlighting trends</p>
<hr />
</div>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>


                

                </article>


    <!-- mathjax config similar to math.stackexchange -->
    <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({ jax: ["input/TeX", "output/HTML-CSS"], tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$']], processEscapes: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }, messageStyle: "none", "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] } });
    </script>
    <script src="./css/MathJax.js.download" id=""></script>

    <iframe scrolling="no" frameborder="0" allowtransparency="true" src="./css/widget_iframe.8f9047c344e062fa7c7ada2fa8332f75.html" title="Twitter settings iframe" style="display: none;"></iframe>
    <div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;">
        <div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_Size2, sans-serif;"></div>
    </div>
    <iframe style="display: none;" src="./css/saved_resource(1).html"></iframe>
</body>

</html>